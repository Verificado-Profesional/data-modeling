{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_95829/1787946145.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('processed_tweets_lemma/train.csv')\n",
    "validation = pd.read_csv('processed_tweets_lemma/validation.csv')\n",
    "test = pd.read_csv('processed_tweets_lemma/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(subset=['texto_normalizado'], inplace=True)\n",
    "validation.dropna(subset=['texto_normalizado'], inplace=True)\n",
    "test.dropna(subset=['texto_normalizado'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conteo_palabras(tweets):\n",
    "    conteo_palabras = defaultdict(int)\n",
    "\n",
    "    for tweet in tweets:\n",
    "        tokens = word_tokenize(tweet)\n",
    "\n",
    "        for token in tokens:\n",
    "            conteo_palabras[token] += 1\n",
    "    \n",
    "    return conteo_palabras\n",
    "\n",
    "conteo_palabras_positivas = conteo_palabras(train[train['sentimiento'] == 2]['texto_normalizado'])\n",
    "\n",
    "conteo_palabras_negativas = conteo_palabras(train[train['sentimiento'] == 1]['texto_normalizado'])\n",
    "\n",
    "conteo_palabras_neutrales = conteo_palabras(train[train['sentimiento'] == 0]['texto_normalizado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tun',\n",
       " 'dulce',\n",
       " 'rbca',\n",
       " 'consultarlas',\n",
       " 'conderuiz',\n",
       " 'mobytohglajs',\n",
       " 'ño',\n",
       " 'trabajo',\n",
       " 'guitarrista',\n",
       " 'prat',\n",
       " 'multicolor',\n",
       " 'clinico',\n",
       " 'generador',\n",
       " 'mafia',\n",
       " 'firmarmelo',\n",
       " 'definido',\n",
       " 'mitinaluche',\n",
       " 'indignado',\n",
       " 'papaya',\n",
       " 'tndrian',\n",
       " 'ramo',\n",
       " 'madrugastes',\n",
       " 'oposición',\n",
       " 'vivos',\n",
       " 'kindle',\n",
       " 'sabra',\n",
       " 'mary',\n",
       " 'economicamente',\n",
       " 'rprodciendo',\n",
       " 'niemeyer',\n",
       " 'encontrarmelo',\n",
       " 'participante',\n",
       " 'bautismo',\n",
       " 'chivasme',\n",
       " 'mucuaa',\n",
       " 'sumarunir',\n",
       " 'custodia',\n",
       " 'rociero',\n",
       " 'careta',\n",
       " 'marido',\n",
       " 'pasivort',\n",
       " 'selva',\n",
       " 'reinsercion',\n",
       " 'rabane',\n",
       " 'condenado',\n",
       " 'bunker',\n",
       " 'mishima',\n",
       " 'servicio',\n",
       " 'paleorefutado',\n",
       " 'chikorita',\n",
       " 'restaurant',\n",
       " 'añoras',\n",
       " 'abundancia',\n",
       " 'oleee',\n",
       " 'prostituido',\n",
       " 'tag',\n",
       " 'redescubrir',\n",
       " 'acostarse',\n",
       " 'panfila',\n",
       " 'compañero',\n",
       " 'ayunt',\n",
       " 'protestar',\n",
       " 'postre',\n",
       " 'atmosferica',\n",
       " 'merecia',\n",
       " 'calderon',\n",
       " 'noooo',\n",
       " 'esperado',\n",
       " 'vaeo',\n",
       " 'leucemia',\n",
       " 'concreto',\n",
       " 'villaverde',\n",
       " 'reixa',\n",
       " 'formato',\n",
       " 'mitologia',\n",
       " 'camacho',\n",
       " 'espanahay',\n",
       " 'amo',\n",
       " 'crespo',\n",
       " 'rollero',\n",
       " 'alegrarnos',\n",
       " 'cena',\n",
       " 'habeis',\n",
       " 'cero',\n",
       " 'palabra',\n",
       " 'rubio',\n",
       " 'ht',\n",
       " 'tertuliapolitica',\n",
       " 'diferencias',\n",
       " 'preceder',\n",
       " 'haceros',\n",
       " 'lanzar',\n",
       " 'sabre',\n",
       " 'historico',\n",
       " 'atracon',\n",
       " 'merezco',\n",
       " 'pedante',\n",
       " 'verteleerte',\n",
       " 'elaborar',\n",
       " 'joiner',\n",
       " 'saludar',\n",
       " 'sii',\n",
       " 'pas',\n",
       " 'chiquilin',\n",
       " 'noelia',\n",
       " 'hiperpersonalizados',\n",
       " 'lopez',\n",
       " 'fresas',\n",
       " 'aqp',\n",
       " 'blay',\n",
       " 'malechor',\n",
       " 'provida',\n",
       " 'chorra',\n",
       " 'estupido',\n",
       " 'darkus',\n",
       " 'esque',\n",
       " 'bondad',\n",
       " 'limpiar',\n",
       " 'utiliza',\n",
       " 'prosanafoods',\n",
       " 'fresh',\n",
       " 'asesinado',\n",
       " 'otsss',\n",
       " 'abajo',\n",
       " 'brom',\n",
       " 'vives',\n",
       " 'tren',\n",
       " 'depositado',\n",
       " 'parfavar',\n",
       " 'quero',\n",
       " 'polvoron',\n",
       " 'vostè',\n",
       " 'sacudio',\n",
       " 'canario',\n",
       " 'financiero',\n",
       " 'paltas',\n",
       " 'posibilitar',\n",
       " 'guardiola',\n",
       " 'cobrador',\n",
       " 'pleno',\n",
       " 'debefundamentalmente',\n",
       " 'prontito',\n",
       " 'ercpp',\n",
       " 'usual',\n",
       " 'creado',\n",
       " 'rencoroso',\n",
       " 'atte',\n",
       " 'desear',\n",
       " 'hombro',\n",
       " 'uso',\n",
       " 'influencia',\n",
       " 'vison',\n",
       " 'cortes',\n",
       " 'asamblea',\n",
       " 'amis',\n",
       " 'olla',\n",
       " 'podais',\n",
       " 'ciclo',\n",
       " 'pañuelos',\n",
       " 'escondi',\n",
       " 'catalán',\n",
       " 'pachanga',\n",
       " 'opinais',\n",
       " 'ana',\n",
       " 'bueh',\n",
       " 'bajaria',\n",
       " 'yuyo',\n",
       " 'bendodo',\n",
       " 'escrutinio',\n",
       " 'clinicas',\n",
       " 'seul',\n",
       " 'facultad',\n",
       " 'paras',\n",
       " 'despedirse',\n",
       " 'apariencia',\n",
       " 'moya',\n",
       " 'lobo',\n",
       " 'digais',\n",
       " 'sa',\n",
       " 'presunc',\n",
       " 'legalizacion',\n",
       " 'què',\n",
       " 'magicos',\n",
       " 'comet',\n",
       " 'pondre',\n",
       " 'susana',\n",
       " 'cuantificar',\n",
       " 'panfleto',\n",
       " 'awesome',\n",
       " 'calmar',\n",
       " 'cuandoabajo',\n",
       " 'reflexion',\n",
       " 'nosoy',\n",
       " 'lasmañanassonmejoressi',\n",
       " 'castigo',\n",
       " 'opositoressolo',\n",
       " 'tofo',\n",
       " 'cubilete',\n",
       " 'pelota',\n",
       " 'funebres',\n",
       " 'factor',\n",
       " 'roberto',\n",
       " 'junta',\n",
       " 'malefica',\n",
       " 'ciudadjardin',\n",
       " 'indigno',\n",
       " 'asistencial',\n",
       " 'ourense',\n",
       " 'constitucional',\n",
       " 'denunciara',\n",
       " 'iberdrola',\n",
       " 'escribo',\n",
       " 'albertito',\n",
       " 'clasico',\n",
       " 'anem',\n",
       " 'ptm',\n",
       " 'cinta',\n",
       " 'tenaz',\n",
       " 'querer',\n",
       " 'suprimir',\n",
       " 'deshoras',\n",
       " 'descubrimiento',\n",
       " 'servidor',\n",
       " 'logra',\n",
       " 'castelar',\n",
       " 'tertuliano',\n",
       " 'feriante',\n",
       " 'biotico',\n",
       " 'mosquito',\n",
       " 'mataojo',\n",
       " 'admirar',\n",
       " 'river',\n",
       " 'juassssss',\n",
       " 'rebelarse',\n",
       " 'nosesipodre',\n",
       " 'estela',\n",
       " 'nombrado',\n",
       " 'culpas',\n",
       " 'saliamos',\n",
       " 'naciste',\n",
       " 'manifestante',\n",
       " 'tronistas',\n",
       " 'bruegel',\n",
       " 'nasa',\n",
       " 'septum',\n",
       " 'perdre',\n",
       " 'registrar',\n",
       " 'targaryen',\n",
       " 'dame',\n",
       " 'incalculable',\n",
       " 'cahuita',\n",
       " 'detain',\n",
       " 'vivir',\n",
       " 'utileria',\n",
       " 's',\n",
       " 'elena',\n",
       " 'gaceta',\n",
       " 'ideologica',\n",
       " 'descanse',\n",
       " 'volverla',\n",
       " 'acudir',\n",
       " 'meruelo',\n",
       " 'mamita',\n",
       " 'bhajan',\n",
       " 'desastre',\n",
       " 'texto',\n",
       " 'cantare',\n",
       " 'puritano',\n",
       " 'sordera',\n",
       " 'mago',\n",
       " 'barçagate',\n",
       " 'forzoso',\n",
       " 'decirnos',\n",
       " 'querra',\n",
       " 'banderitan',\n",
       " 'titulos',\n",
       " 'agradezco',\n",
       " 'ritaalcaldesa',\n",
       " 'ridicula',\n",
       " 'meteras',\n",
       " 'proporcionadaprimaveraestudiantil',\n",
       " 'regulacion',\n",
       " 'dl',\n",
       " 'icons',\n",
       " 'reprobable',\n",
       " 'contribuir',\n",
       " 'review',\n",
       " 'ccc',\n",
       " 'perfecto',\n",
       " 'vamos',\n",
       " 'nostros',\n",
       " 'adoro',\n",
       " 'estres',\n",
       " 'evidente',\n",
       " 'generalmente',\n",
       " 'fatxes',\n",
       " 'instalar',\n",
       " 'posibilidad',\n",
       " 'partner',\n",
       " 'pronta',\n",
       " 'costoefectivo',\n",
       " 'efimeros',\n",
       " 'estructuralesimportantes',\n",
       " 'estrechar',\n",
       " 'hijoterraja',\n",
       " 'astillero',\n",
       " 'clientelismo',\n",
       " 'futbolsi',\n",
       " 'agustin',\n",
       " 'wonderbra',\n",
       " 'calentido',\n",
       " 'remontar',\n",
       " 'escandalizado',\n",
       " 'retorica',\n",
       " 'llovera',\n",
       " 'sistemica',\n",
       " 'tomarte',\n",
       " 'publicitaria',\n",
       " 'prudente',\n",
       " 'votais',\n",
       " 'duda',\n",
       " 'buenopoco',\n",
       " 'elmento',\n",
       " 'ronque',\n",
       " 'ar',\n",
       " 'borrell',\n",
       " 'escarchado',\n",
       " 'herodes',\n",
       " 'porfavor',\n",
       " 'actualizado',\n",
       " 'don',\n",
       " 'conservar',\n",
       " 'pelis',\n",
       " 'subaru',\n",
       " 'magdalena',\n",
       " 'localidad',\n",
       " 'pudieron',\n",
       " 'chocolate',\n",
       " 'contandote',\n",
       " 'animo',\n",
       " 'heads',\n",
       " 'enchilado',\n",
       " 'veiamos',\n",
       " 'ncntba',\n",
       " 'cadiz',\n",
       " 'podra',\n",
       " 'trineo',\n",
       " 'frente',\n",
       " 'fcb',\n",
       " 'inconveniente',\n",
       " 'send',\n",
       " 'respondi',\n",
       " 'chido',\n",
       " 'indispensable',\n",
       " 'escogerla',\n",
       " 'asi',\n",
       " 'grassias',\n",
       " 'coffee',\n",
       " 'encender',\n",
       " 'impulso',\n",
       " 'huacho',\n",
       " 'robot',\n",
       " 'intoxicadoresdejornadaelectoral',\n",
       " 'paciente',\n",
       " 'impunidad',\n",
       " 'high',\n",
       " 'habitante',\n",
       " 'presidnt',\n",
       " 'serrano',\n",
       " 'especular',\n",
       " 'honrado',\n",
       " 'comision',\n",
       " 'dudeis',\n",
       " 'vencer',\n",
       " 'chinga',\n",
       " 'acreditar',\n",
       " 'preveia',\n",
       " 'provocado',\n",
       " 'posgrado',\n",
       " 'estrella',\n",
       " 'arquitecto',\n",
       " 'chueca',\n",
       " 'sobrepeso',\n",
       " 'deputacions',\n",
       " 'cañadareal',\n",
       " 'inesperado',\n",
       " 'gigantesco',\n",
       " 'parecerme',\n",
       " 'transparencia',\n",
       " 'hermosoes',\n",
       " 'entrega',\n",
       " 'tenia',\n",
       " 'votapsoe',\n",
       " 'familia',\n",
       " 'loquito',\n",
       " 'esfuerzo',\n",
       " 'decimo',\n",
       " 'escoger',\n",
       " 'liberalismo',\n",
       " 'contaminacion',\n",
       " 'derrotista',\n",
       " 'insinua',\n",
       " 'trasplantes',\n",
       " 'podamos',\n",
       " 'consonante',\n",
       " 'compadre',\n",
       " 'tazloco',\n",
       " 'astoria',\n",
       " 'aportacion',\n",
       " 'sigues',\n",
       " 'chaz',\n",
       " 'oswar',\n",
       " 'lego',\n",
       " 'competencia',\n",
       " 'retenido',\n",
       " 'paremosalppvotapsoe',\n",
       " 'romano',\n",
       " 'sandwich',\n",
       " 'escucha',\n",
       " 'wws',\n",
       " 'sindical',\n",
       " 'mremod',\n",
       " 'preferiria',\n",
       " 'desviar',\n",
       " 'leñador',\n",
       " 'veere',\n",
       " 'moar',\n",
       " 'pe',\n",
       " 'andarle',\n",
       " 'lupita',\n",
       " 'mercado',\n",
       " 'prejubilado',\n",
       " 'calmarme',\n",
       " 'puigcerdà',\n",
       " 'experto',\n",
       " 'trotsky',\n",
       " 'vencida',\n",
       " 'progresista',\n",
       " 'mediador',\n",
       " 'igualito',\n",
       " 'podemos',\n",
       " 'tertuliana',\n",
       " 'universidad',\n",
       " 'aliado',\n",
       " 'peroen',\n",
       " 'mandala',\n",
       " 'facu',\n",
       " 'endeudamiento',\n",
       " 'tqm',\n",
       " 'kamen',\n",
       " 'colocacion',\n",
       " 'nats',\n",
       " 'diversion',\n",
       " 'cartelito',\n",
       " 'alleged',\n",
       " 'traidor',\n",
       " 'apareci',\n",
       " 'cdu',\n",
       " 'sendos',\n",
       " 'absolucion',\n",
       " 'perfaono',\n",
       " 'discursorajoy',\n",
       " 'abucheo',\n",
       " 'contenido',\n",
       " 'giorgio',\n",
       " 'madrazo',\n",
       " 'tocar',\n",
       " 'entidad',\n",
       " 'gafas',\n",
       " 'community',\n",
       " 'presencia',\n",
       " 'inq',\n",
       " 'cortito',\n",
       " 'vistazo',\n",
       " 'reemplazo',\n",
       " 'arbitraje',\n",
       " 'tattos',\n",
       " 'pez',\n",
       " 'indique',\n",
       " 'menor',\n",
       " 'posponer',\n",
       " 'huracanado',\n",
       " 'arniches',\n",
       " 'ello',\n",
       " 'sanguchitos',\n",
       " 'encinas',\n",
       " 'cgpj',\n",
       " 'joker',\n",
       " 'gemma',\n",
       " 'user',\n",
       " 'sospechoso',\n",
       " 'revolucionar',\n",
       " 'dudar',\n",
       " 'antojarse',\n",
       " 'ayeresper',\n",
       " 'quejeis',\n",
       " 'horrible',\n",
       " 'gignac',\n",
       " 'haesoo',\n",
       " 'roquillos',\n",
       " 'remonta',\n",
       " 'sectarismo',\n",
       " 'perdersebuen',\n",
       " 'claroel',\n",
       " 'c',\n",
       " 'sobreconfiado',\n",
       " 'andres',\n",
       " 'alba',\n",
       " 'frenillo',\n",
       " 'buenisimos',\n",
       " 'wyomings',\n",
       " 'margallo',\n",
       " 'profesortutor',\n",
       " 'ansiedad',\n",
       " 'yay',\n",
       " 'gorlero',\n",
       " 'amargar',\n",
       " 'feriado',\n",
       " 'cancioncita',\n",
       " 'disciplina',\n",
       " 'volumen',\n",
       " 'maaaa',\n",
       " 'ampiquestcomo',\n",
       " 'chiste',\n",
       " 'euco',\n",
       " 'mareo',\n",
       " 'huerta',\n",
       " 'franck',\n",
       " 'ballon',\n",
       " 'trague',\n",
       " 'imaginaroslo',\n",
       " 'messi',\n",
       " 'cosa',\n",
       " 'dualidad',\n",
       " 'borrachera',\n",
       " 'jartani',\n",
       " 'lachispadelavida',\n",
       " 'malisimo',\n",
       " 'sacalo',\n",
       " 'dixo',\n",
       " 'roldar',\n",
       " 'raquel',\n",
       " 'llamar',\n",
       " 'legal',\n",
       " 'calefaccion',\n",
       " 'conformar',\n",
       " 'armada',\n",
       " 'sindicatosceoe',\n",
       " 'grafico',\n",
       " 'verdadahora',\n",
       " 'tranquilidad',\n",
       " 'david',\n",
       " 'grinan',\n",
       " 'chavo',\n",
       " 'menudiario',\n",
       " 'tintinhe',\n",
       " 'otriginal',\n",
       " 'diascomienza',\n",
       " 'lunch',\n",
       " 'lindonostalgias',\n",
       " 'cfr',\n",
       " 'resucitar',\n",
       " 'traicionar',\n",
       " 'grasa',\n",
       " 'jugador',\n",
       " 'colapsar',\n",
       " 'zar',\n",
       " 'alaaaaaaaa',\n",
       " 'nba',\n",
       " 'anteproyecto',\n",
       " 'casablanca',\n",
       " 'ojeras',\n",
       " 'malvinas',\n",
       " 'perdon',\n",
       " 'corrido',\n",
       " 'cobro',\n",
       " 'sonata',\n",
       " 'desatender',\n",
       " 'berni',\n",
       " 'vista',\n",
       " 'tiempo',\n",
       " 'peña',\n",
       " 'superbieeeeeeennnnnn',\n",
       " 'aliron',\n",
       " 'abrigaditos',\n",
       " 'nuñez',\n",
       " 'canelas',\n",
       " 'mundooooo',\n",
       " 'manipulacion',\n",
       " 'oro',\n",
       " 'volvera',\n",
       " 'audiencias',\n",
       " 'pag',\n",
       " 'solemne',\n",
       " 'absentismo',\n",
       " 'genral',\n",
       " 'dichoso',\n",
       " 'absoluto',\n",
       " 'perfume',\n",
       " 'alrededor',\n",
       " 'yaaaaa',\n",
       " 'puder',\n",
       " 'book',\n",
       " 'nido',\n",
       " 'quiebraeso',\n",
       " 'roqy',\n",
       " 'kisses',\n",
       " 'orbytes',\n",
       " 'pacificoen',\n",
       " 'abstención',\n",
       " 'causa',\n",
       " 'vieneeeeela',\n",
       " 'excusasparallegartarde',\n",
       " 'memoriahistorica',\n",
       " 'cntrata',\n",
       " 'bnoches',\n",
       " 'futbolero',\n",
       " 'añosh',\n",
       " 'star',\n",
       " 'oriente',\n",
       " 'quiz',\n",
       " 'mitinpp',\n",
       " 'iva',\n",
       " 'pudor',\n",
       " 'juanitosiemprepresente',\n",
       " 'intereconomia',\n",
       " 'constante',\n",
       " 'dictamen',\n",
       " 'persistir',\n",
       " 'bipartidista',\n",
       " 'acabant',\n",
       " 'carnitas',\n",
       " 'elementos',\n",
       " 'perfectamente',\n",
       " 'ofi',\n",
       " 'sombra',\n",
       " 'grotesco',\n",
       " 'lleida',\n",
       " 'chicks',\n",
       " 'analogico',\n",
       " 'rebosa',\n",
       " 'apuesta',\n",
       " 'ahora',\n",
       " 'ajaja',\n",
       " 'defensor',\n",
       " 'participacion',\n",
       " 'villanuevadelarzobispo',\n",
       " 'sacalagua',\n",
       " 'gossip',\n",
       " 'panda',\n",
       " 'bonica',\n",
       " 'fet',\n",
       " 'organizar',\n",
       " 'primero',\n",
       " 'bertosin',\n",
       " 'concluye',\n",
       " 'regañar',\n",
       " 'barbate',\n",
       " 'informe',\n",
       " 'calculadora',\n",
       " 'mìnima',\n",
       " 'comparativo',\n",
       " 'laporta',\n",
       " 'rodear',\n",
       " 'toy',\n",
       " 'probe',\n",
       " 'chillar',\n",
       " 'haria',\n",
       " 'art',\n",
       " 'prostitucion',\n",
       " 'apostais',\n",
       " 'red',\n",
       " 'volcan',\n",
       " 'establecera',\n",
       " 'respuestas',\n",
       " 'chill',\n",
       " 'robarme',\n",
       " 'decimotercro',\n",
       " 'empiece',\n",
       " 'keith',\n",
       " 'izquierdasy',\n",
       " 'autonomas',\n",
       " 'malita',\n",
       " 'noska',\n",
       " 'santi',\n",
       " 'personasen',\n",
       " 'mesa',\n",
       " 'rencor',\n",
       " 'mamado',\n",
       " 'hope',\n",
       " 'vapes',\n",
       " 'goya',\n",
       " 'deponer',\n",
       " 'alternativa',\n",
       " 'martadelcastillo',\n",
       " 'sl',\n",
       " 'alarmar',\n",
       " 'winchester',\n",
       " 'pelar',\n",
       " 'eeggll',\n",
       " 'ejema',\n",
       " 'noviembre',\n",
       " 'cameos',\n",
       " 'telefonico',\n",
       " 'hermandad',\n",
       " 'burguesas',\n",
       " 'bobo',\n",
       " 'densa',\n",
       " 'briceño',\n",
       " 'espanyol',\n",
       " 'graciasayer',\n",
       " 'parejitas',\n",
       " 'audifonos',\n",
       " 'acontecimiento',\n",
       " 'mochila',\n",
       " 'imputado',\n",
       " 'palahniuk',\n",
       " 'unu',\n",
       " 'metro',\n",
       " 'pretexto',\n",
       " 'embudo',\n",
       " 'agrar',\n",
       " 'feministaltemgt',\n",
       " 'a',\n",
       " 'loconavidadeslight',\n",
       " 'cuidarte',\n",
       " 'subcampeon',\n",
       " 'mandas',\n",
       " 'echar',\n",
       " 'casabuenos',\n",
       " 'friamente',\n",
       " 'mercader',\n",
       " 'minoritarios',\n",
       " 'ileso',\n",
       " 'versi',\n",
       " 'plenario',\n",
       " 'lavarla',\n",
       " 'ibamos',\n",
       " 'volem',\n",
       " 'teles',\n",
       " 'posiblemente',\n",
       " 'vanessa',\n",
       " 'bola',\n",
       " 'soria',\n",
       " 'arta',\n",
       " 'posicion',\n",
       " 'transmitirnos',\n",
       " 'insisto',\n",
       " 'terra',\n",
       " 'lago',\n",
       " 'perdurar',\n",
       " 'imparable',\n",
       " 'ducho',\n",
       " 'ignacio',\n",
       " 'party',\n",
       " 'glotoneria',\n",
       " 'friday',\n",
       " 'deprisa',\n",
       " 'etapa',\n",
       " 'secuaz',\n",
       " 'lema',\n",
       " 'manda',\n",
       " 'competente',\n",
       " 'colgado',\n",
       " 'tods',\n",
       " 'negativa',\n",
       " 'ellasin',\n",
       " 'conservacion',\n",
       " 'desgraciadamente',\n",
       " 'minoritario',\n",
       " 'biografico',\n",
       " 'liquidar',\n",
       " 'eolicas',\n",
       " 'haberme',\n",
       " 'pairas',\n",
       " 'andabamos',\n",
       " 'llorar',\n",
       " 'libertaddigitalcomnacional',\n",
       " 'inolvidable',\n",
       " 'mismom',\n",
       " 'kbza',\n",
       " 'fanar',\n",
       " 'angeles',\n",
       " 'defraudado',\n",
       " 'marvel',\n",
       " 'empatado',\n",
       " 'pudieran',\n",
       " 'desventura',\n",
       " 'prontita',\n",
       " 'vesolosi',\n",
       " 'andate',\n",
       " 'tacawertz',\n",
       " 'enamorado',\n",
       " 'todavia',\n",
       " 'umbral',\n",
       " 'fòrum',\n",
       " 'cheers',\n",
       " 'tmr',\n",
       " 'sancionado',\n",
       " 'esoesloquemola',\n",
       " 'ideamillonaria',\n",
       " 'tronar',\n",
       " 'rulos',\n",
       " 'posta',\n",
       " 'rumania',\n",
       " 'tapón',\n",
       " 'ningún',\n",
       " 'loewe',\n",
       " 'exista',\n",
       " 'carrillismo',\n",
       " 'grupomixto',\n",
       " 'comic',\n",
       " 'cronico',\n",
       " 'delenda',\n",
       " 'hagais',\n",
       " 'haba',\n",
       " 'jona',\n",
       " 'terminar',\n",
       " 'contestarles',\n",
       " 'inspirador',\n",
       " 'sustituir',\n",
       " 'transporte',\n",
       " 'rie',\n",
       " 'ladilla',\n",
       " 'conoserte',\n",
       " 'asustado',\n",
       " 'mitings',\n",
       " 'vacaciones',\n",
       " 'dilema',\n",
       " 'trocar',\n",
       " 'sprite',\n",
       " 'tomarme',\n",
       " 'empedar',\n",
       " 'muuucho',\n",
       " 'managerestaria',\n",
       " 'ridao',\n",
       " 'conspirar',\n",
       " 'opacidadcorrupcion',\n",
       " 'vull',\n",
       " 'gobiernoaa',\n",
       " 'fun',\n",
       " 'seguirme',\n",
       " 'prepa',\n",
       " 'diu',\n",
       " 'bendita',\n",
       " 'navideñomari',\n",
       " 'cruzar',\n",
       " 'esforzandose',\n",
       " 'agredido',\n",
       " 'valer',\n",
       " 'moncho',\n",
       " 'maricarmen',\n",
       " 'tema',\n",
       " 'amar',\n",
       " 'repensarse',\n",
       " 'aburrarse',\n",
       " 'bondadoso',\n",
       " 'pontevedra',\n",
       " 'caramba',\n",
       " 'olvidar',\n",
       " 'arrepentido',\n",
       " 'acurrucadita',\n",
       " 'causado',\n",
       " 'aprovechandoeltuit',\n",
       " 'ryszard',\n",
       " 'exconsejero',\n",
       " 'pesadilla',\n",
       " 'juntitos',\n",
       " 'qsf',\n",
       " 'cruzado',\n",
       " 'caere',\n",
       " 'griñan',\n",
       " 'coordinador',\n",
       " 'inspiracion',\n",
       " 'stennis',\n",
       " 'requerir',\n",
       " 'pobrecito',\n",
       " 'proyect',\n",
       " 'gol',\n",
       " 'telmo',\n",
       " 'forestal',\n",
       " 'ladrillasos',\n",
       " 'rayo',\n",
       " 'estariais',\n",
       " 'cdmx',\n",
       " 'pluriempleo',\n",
       " 'negocio',\n",
       " 'educacion',\n",
       " 'consecuente',\n",
       " 'presente',\n",
       " 'satanico',\n",
       " 'ford',\n",
       " 'uedila',\n",
       " 'muchs',\n",
       " 'isla',\n",
       " 'coment',\n",
       " 'so',\n",
       " 'gobernante',\n",
       " 'hidrologico',\n",
       " 'muamba',\n",
       " 'tipologia',\n",
       " 'trepa',\n",
       " 'alfa',\n",
       " 'francotirador',\n",
       " 'taxista',\n",
       " 'pie',\n",
       " 'ampliar',\n",
       " 'avt',\n",
       " 'flamante',\n",
       " 'descargues',\n",
       " 'trasmano',\n",
       " 'vdeoclip',\n",
       " 'seriamente',\n",
       " 'avance',\n",
       " 'diferente',\n",
       " 'magaluf',\n",
       " '\\x93varapalo',\n",
       " 'poneros',\n",
       " 'puedes',\n",
       " 'inhabilitado',\n",
       " 'estrenojackysugemela',\n",
       " 'clasificacion',\n",
       " 'flotador',\n",
       " 'urkullu',\n",
       " 'existierany',\n",
       " 'uña',\n",
       " 'hangouts',\n",
       " 'yojaja',\n",
       " 'escucharse',\n",
       " 'picadura',\n",
       " 'celular',\n",
       " 'pin',\n",
       " 'yucatan',\n",
       " 'lechera',\n",
       " 'you',\n",
       " 'defende',\n",
       " 'oidoguapobonito',\n",
       " 'retwittealo',\n",
       " 'diseñar',\n",
       " 'espolón',\n",
       " 'fijar',\n",
       " 'juegazos',\n",
       " 'mari',\n",
       " 'tratare',\n",
       " 'ladron',\n",
       " 'aguirre',\n",
       " 'arte¿religioso¿tener',\n",
       " 'impecable',\n",
       " 'salario',\n",
       " 'ppc',\n",
       " 'jajart',\n",
       " 'condomina',\n",
       " 'arg',\n",
       " 'delirio',\n",
       " 'vote',\n",
       " 'pueblo',\n",
       " 'gradprepatec',\n",
       " 'daniela',\n",
       " 'adolfo',\n",
       " 'allende',\n",
       " 'temperatura',\n",
       " 'romney',\n",
       " 'paula',\n",
       " 'exclusion',\n",
       " 'arriba',\n",
       " 'suicide',\n",
       " 'montes',\n",
       " 'muwi',\n",
       " 'carril',\n",
       " 'acompañarme',\n",
       " 'nlv',\n",
       " 'republicana',\n",
       " 'mejorable',\n",
       " 'knicks',\n",
       " 'sinverguenzas',\n",
       " 'aporte',\n",
       " 'determinado',\n",
       " 'sures',\n",
       " 'mijas',\n",
       " 'secretaria',\n",
       " 'estaños',\n",
       " 'usandolos',\n",
       " 'matiz',\n",
       " 'importancia',\n",
       " 'celebracion',\n",
       " 'trama',\n",
       " 'gustarte',\n",
       " 'humanitariaese',\n",
       " 'vamo',\n",
       " 'llevare',\n",
       " 'equo',\n",
       " 'suena',\n",
       " 'retroceso',\n",
       " 'detallarlo',\n",
       " 'brasileño',\n",
       " 'ilusionel',\n",
       " 'vuelvobudapest',\n",
       " 'entristecer',\n",
       " 'colorante',\n",
       " 'espalda',\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabras_set = set(conteo_palabras_positivas.keys()).union(set(conteo_palabras_negativas.keys()))\n",
    "palabras_set = palabras_set.union(set(conteo_palabras_neutrales.keys()))\n",
    "palabras_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tweets(tweets, ys):\n",
    "    result = {}\n",
    "\n",
    "    for y, tweet in zip(ys, tweets):\n",
    "        for word in word_tokenize(tweet):\n",
    "            pair = (word,y)\n",
    "\n",
    "            if pair in result:\n",
    "                result[pair] += 1\n",
    "            else:\n",
    "                result[pair] = 1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(freqs, word, label):\n",
    "    n = 0  \n",
    "\n",
    "    pair = (word, label)\n",
    "    if (pair in freqs):\n",
    "        n = freqs[pair]\n",
    "\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes1(freqs, train_x, train_y):\n",
    "    loglikelihood_pos = {}\n",
    "    loglikelihood_neg = {}\n",
    "    loglikelihood_neu = {}\n",
    "\n",
    "    vocab = set([pair[0] for pair in freqs.keys()])\n",
    "    V = len(vocab)\n",
    "\n",
    "    N_pos = N_neg = N_neu = 0\n",
    "    for pair in freqs.keys():\n",
    "        if pair[1] == 2:\n",
    "            N_pos += freqs[pair]\n",
    "        elif pair[1] == 1:\n",
    "            N_neg += freqs[pair]\n",
    "        else:\n",
    "            N_neu += freqs[pair]\n",
    "    \n",
    "    logprior_pos = np.log(N_pos / (N_pos + N_neg + N_neu))\n",
    "    logprior_neg = np.log(N_neg / (N_pos + N_neg + N_neu))\n",
    "    logprior_neu = np.log(N_neu / (N_pos + N_neg + N_neu))\n",
    "\n",
    "    for word in vocab:\n",
    "        freq_pos =lookup(freqs,word,2)\n",
    "        freq_neg =lookup(freqs,word,1)\n",
    "        freq_neu =lookup(freqs,word,0)\n",
    "\n",
    "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
    "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
    "        p_w_neu = (freq_neu + 1) / (N_neu + V)\n",
    "\n",
    "        loglikelihood_pos[word] = np.log(p_w_pos) - np.log(p_w_neg + p_w_neu)\n",
    "        loglikelihood_neg[word] = np.log(p_w_neg) - np.log(p_w_pos + p_w_neu)\n",
    "        loglikelihood_neu[word] = np.log(p_w_neu) - np.log(p_w_pos + p_w_neg)\n",
    "\n",
    "    return loglikelihood_pos, loglikelihood_neg, loglikelihood_neu, logprior_pos, logprior_neg, logprior_neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict1(tweet, logprior_pos, logprior_neg, logprior_neu, loglikelihood_pos,loglikelihood_neg, loglikelihood_neu):\n",
    "    word_l = word_tokenize(tweet)\n",
    "\n",
    "    p_pos = logprior_pos\n",
    "    p_neg = logprior_neg\n",
    "    p_neu = logprior_neu\n",
    "\n",
    "    for word in word_l:\n",
    "\n",
    "        if word in loglikelihood_pos:\n",
    "            p_pos += loglikelihood_pos[word]\n",
    "        if word in loglikelihood_neg:\n",
    "            p_neg += loglikelihood_neg[word]\n",
    "        if word in loglikelihood_neu:\n",
    "            p_neu += loglikelihood_neu[word]\n",
    "\n",
    "    return {2: p_pos, 1: p_neg, 0: p_neu}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs1 = count_tweets(train.texto_normalizado, train.sentimiento)\n",
    "loglikelihood_pos, loglikelihood_neg, loglikelihood_neu, logprior_pos, logprior_neg, logprior_neu = train_naive_bayes1(freqs1, train.texto_normalizado, train.sentimiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation['prediccion'] = validation['texto_normalizado'].apply(lambda x: max(naive_bayes_predict1(x,logprior_pos, logprior_neg, logprior_neu, loglikelihood_pos,loglikelihood_neg, loglikelihood_neu), key=naive_bayes_predict1(x, logprior_pos, logprior_neg, logprior_neu, loglikelihood_pos,loglikelihood_neg, loglikelihood_neu).get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>texto_normalizado</th>\n",
       "      <th>prediccion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7450</td>\n",
       "      <td>@marianorajoy Estamos muy satisfechos</td>\n",
       "      <td>2</td>\n",
       "      <td>satisfecho</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1332</td>\n",
       "      <td>Nada mejor que pasar la navidad con la familia...</td>\n",
       "      <td>2</td>\n",
       "      <td>mejor pasar navidad familia amigo uds pasar</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6436</td>\n",
       "      <td>Planeta creativo: nuevo placer otra interesant...</td>\n",
       "      <td>2</td>\n",
       "      <td>planeta creativo nuevo placer interesante jorn...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8973</td>\n",
       "      <td>Necesito ir a mi hogar y dormir con mis dos hi...</td>\n",
       "      <td>1</td>\n",
       "      <td>necesitar ir hogar dormir dos hijo peludos kab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>803</td>\n",
       "      <td>En la XII edición Premios Culturas de Extremad...</td>\n",
       "      <td>2</td>\n",
       "      <td>xii edicion premio culturas extremadura galard...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3409</th>\n",
       "      <td>15367</td>\n",
       "      <td>Bajando a Calahorra ya no queda nada para el c...</td>\n",
       "      <td>2</td>\n",
       "      <td>bajar calahorra quedar cambio junto salir adel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410</th>\n",
       "      <td>10591</td>\n",
       "      <td>Es que estos dolores, son bárbaros...</td>\n",
       "      <td>1</td>\n",
       "      <td>dolor barbaros</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3411</th>\n",
       "      <td>2111</td>\n",
       "      <td>#ChacónenLaSER : \"Me siento con capacidad y co...</td>\n",
       "      <td>2</td>\n",
       "      <td>chaconenlaser sentar capacidad equipo superman...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3412</th>\n",
       "      <td>14924</td>\n",
       "      <td>La Prima de Riesgo es 1 estafa de los Mercados...</td>\n",
       "      <td>0</td>\n",
       "      <td>prima riesgo estafa mercado bastar ppsoe basta...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>13242</td>\n",
       "      <td>Por que existe gente bruta !!! Que cuando ven ...</td>\n",
       "      <td>1</td>\n",
       "      <td>exir gente bruta venir zapatilla nuevo pisar p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3405 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              texto  \\\n",
       "0           7450             @marianorajoy Estamos muy satisfechos    \n",
       "1           1332  Nada mejor que pasar la navidad con la familia...   \n",
       "2           6436  Planeta creativo: nuevo placer otra interesant...   \n",
       "3           8973  Necesito ir a mi hogar y dormir con mis dos hi...   \n",
       "4            803  En la XII edición Premios Culturas de Extremad...   \n",
       "...          ...                                                ...   \n",
       "3409       15367  Bajando a Calahorra ya no queda nada para el c...   \n",
       "3410       10591              Es que estos dolores, son bárbaros...   \n",
       "3411        2111  #ChacónenLaSER : \"Me siento con capacidad y co...   \n",
       "3412       14924  La Prima de Riesgo es 1 estafa de los Mercados...   \n",
       "3413       13242  Por que existe gente bruta !!! Que cuando ven ...   \n",
       "\n",
       "      sentimiento                                  texto_normalizado  \\\n",
       "0               2                                         satisfecho   \n",
       "1               2        mejor pasar navidad familia amigo uds pasar   \n",
       "2               2  planeta creativo nuevo placer interesante jorn...   \n",
       "3               1  necesitar ir hogar dormir dos hijo peludos kab...   \n",
       "4               2  xii edicion premio culturas extremadura galard...   \n",
       "...           ...                                                ...   \n",
       "3409            2  bajar calahorra quedar cambio junto salir adel...   \n",
       "3410            1                                     dolor barbaros   \n",
       "3411            2  chaconenlaser sentar capacidad equipo superman...   \n",
       "3412            0  prima riesgo estafa mercado bastar ppsoe basta...   \n",
       "3413            1  exir gente bruta venir zapatilla nuevo pisar p...   \n",
       "\n",
       "      prediccion  \n",
       "0              0  \n",
       "1              2  \n",
       "2              2  \n",
       "3              1  \n",
       "4              2  \n",
       "...          ...  \n",
       "3409           0  \n",
       "3410           1  \n",
       "3411           1  \n",
       "3412           1  \n",
       "3413           1  \n",
       "\n",
       "[3405 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediccion\n",
       "1    767\n",
       "2    746\n",
       "0    370\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation[validation['sentimiento'] == validation['prediccion']].prediccion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentimiento\n",
       "0    724\n",
       "1    415\n",
       "2    383\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation[validation['sentimiento'] != validation['prediccion']].sentimiento.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[370 374 350]\n",
      " [233 767 182]\n",
      " [184 199 746]]\n",
      "Precision: [0.47013977 0.57238806 0.58372457]\n",
      "Recall: [0.33820841 0.64890017 0.66076174]\n",
      "Accuracy: 0.5530102790014684\n",
      "F1 Score: [0.39340776 0.60824742 0.61985875]\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusión\n",
    "cm = confusion_matrix(validation['sentimiento'], validation['prediccion'])\n",
    "\n",
    "precision = precision_score(validation['sentimiento'], validation['prediccion'], average=None)\n",
    "recall = recall_score(validation['sentimiento'], validation['prediccion'], average=None)\n",
    "accuracy = accuracy_score(validation['sentimiento'], validation['prediccion'])\n",
    "\n",
    "f1 = f1_score(validation['sentimiento'], validation['prediccion'], average=None)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo sin neutrales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nb = train[train['sentimiento'] != 0]\n",
    "validation_nb = validation[validation['sentimiento'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_95829/2834200813.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_nb['sentimiento'] = train_nb['sentimiento'].apply(lambda x: 1 if x == 2 else 0)\n",
      "/tmp/ipykernel_95829/2834200813.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_nb['sentimiento'] = validation_nb['sentimiento'].apply(lambda x: 1 if x == 2 else 0)\n"
     ]
    }
   ],
   "source": [
    "train_nb['sentimiento'] = train_nb['sentimiento'].apply(lambda x: 1 if x == 2 else 0)\n",
    "validation_nb['sentimiento'] = validation_nb['sentimiento'].apply(lambda x: 1 if x == 2 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>texto_normalizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10221</td>\n",
       "      <td>@Manuellflorod Bienvenida (triste) realidad, a...</td>\n",
       "      <td>0</td>\n",
       "      <td>bienvenida triste realidad andar mismo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9565</td>\n",
       "      <td>Estar en los brazos de mi novio es lo único qu...</td>\n",
       "      <td>1</td>\n",
       "      <td>brazo novio unico querer necesitar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7713</td>\n",
       "      <td>@ahorapodemos @ierrejon Tambien que las empres...</td>\n",
       "      <td>1</td>\n",
       "      <td>tambien empresa independiente contactar si ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1038</td>\n",
       "      <td>El tono duro y sin concesiones de la réplica d...</td>\n",
       "      <td>0</td>\n",
       "      <td>tono duro concesión replica rajoy amaiur anunc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>Bdías. EM no se ira de puente. Si vosotros os ...</td>\n",
       "      <td>1</td>\n",
       "      <td>bdias em ira puente si ir dejeis llevar tablet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10236</th>\n",
       "      <td>11285</td>\n",
       "      <td>No, solo quiero bailarte la medusa loca en pri...</td>\n",
       "      <td>1</td>\n",
       "      <td>solo querer bailarte medusa loca privado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10237</th>\n",
       "      <td>11965</td>\n",
       "      <td>@cuervotinelli lo único que te puse fue que qu...</td>\n",
       "      <td>0</td>\n",
       "      <td>unico poner queria jugar lolo tortuga retwitte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10238</th>\n",
       "      <td>5390</td>\n",
       "      <td>La Audiencia Nacional condena a 20 años de pri...</td>\n",
       "      <td>0</td>\n",
       "      <td>audiencia nacional condena año prision ex jefe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10239</th>\n",
       "      <td>860</td>\n",
       "      <td>RT @eP_Titulares: #Sociedad Muere apuñalada la...</td>\n",
       "      <td>0</td>\n",
       "      <td>sociedad muere apuñalado propietario zapateria...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10240</th>\n",
       "      <td>15796</td>\n",
       "      <td>. @UPyD una sanidad y educación común y De cal...</td>\n",
       "      <td>1</td>\n",
       "      <td>sanidad educacion comun calidad español nup...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6863 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              texto  \\\n",
       "0           10221  @Manuellflorod Bienvenida (triste) realidad, a...   \n",
       "1            9565  Estar en los brazos de mi novio es lo único qu...   \n",
       "3            7713  @ahorapodemos @ierrejon Tambien que las empres...   \n",
       "5            1038  El tono duro y sin concesiones de la réplica d...   \n",
       "7              10  Bdías. EM no se ira de puente. Si vosotros os ...   \n",
       "...           ...                                                ...   \n",
       "10236       11285  No, solo quiero bailarte la medusa loca en pri...   \n",
       "10237       11965  @cuervotinelli lo único que te puse fue que qu...   \n",
       "10238        5390  La Audiencia Nacional condena a 20 años de pri...   \n",
       "10239         860  RT @eP_Titulares: #Sociedad Muere apuñalada la...   \n",
       "10240       15796  . @UPyD una sanidad y educación común y De cal...   \n",
       "\n",
       "       sentimiento                                  texto_normalizado  \n",
       "0                0             bienvenida triste realidad andar mismo  \n",
       "1                1                 brazo novio unico querer necesitar  \n",
       "3                1     tambien empresa independiente contactar si ...  \n",
       "5                0  tono duro concesión replica rajoy amaiur anunc...  \n",
       "7                1  bdias em ira puente si ir dejeis llevar tablet...  \n",
       "...            ...                                                ...  \n",
       "10236            1           solo querer bailarte medusa loca privado  \n",
       "10237            0  unico poner queria jugar lolo tortuga retwitte...  \n",
       "10238            0  audiencia nacional condena año prision ex jefe...  \n",
       "10239            0  sociedad muere apuñalado propietario zapateria...  \n",
       "10240            1     sanidad educacion comun calidad español nup...  \n",
       "\n",
       "[6863 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(freqs, word, label):\n",
    "    n = 0  \n",
    "\n",
    "    pair = (word, label)\n",
    "    if (pair in freqs):\n",
    "        n = freqs[pair]\n",
    "\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(freqs, train_x, train_y):\n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "\n",
    "    vocab = palabras_set\n",
    "    V = len(vocab)\n",
    "\n",
    "    N_pos = N_neg = 0\n",
    "    for pair in freqs.keys():\n",
    "        if pair[1] > 0:\n",
    "            N_pos += freqs[pair]\n",
    "        else:\n",
    "            N_neg += freqs[pair]\n",
    "\n",
    "    D = len(train_y)\n",
    "    D_pos =np.sum(train_y)\n",
    "    D_neg = D-D_pos\n",
    "\n",
    "    logprior =np.log(D_pos) - np.log(D_neg)\n",
    "\n",
    "    for word in vocab:\n",
    "        freq_pos =lookup(freqs,word,1)\n",
    "        freq_neg =lookup(freqs,word,0)\n",
    "\n",
    "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
    "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
    "\n",
    "        loglikelihood[word] = np.log(p_w_pos/p_w_neg)\n",
    "\n",
    "    return logprior, loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = count_tweets(train_nb.texto_normalizado, train_nb.sentimiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprior, loglikelihood = train_naive_bayes(freqs, train_nb.texto_normalizado, train_nb.sentimiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict(tweet, logprior, loglikelihood):\n",
    "    word_l = word_tokenize(tweet)\n",
    "    p = 0\n",
    "    p += logprior\n",
    "\n",
    "    for word in word_l:\n",
    "        if word in loglikelihood:\n",
    "            p += loglikelihood[word]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tweet = 'pesimo horrible bueno hermoso'\n",
    "p = naive_bayes_predict(my_tweet, logprior, loglikelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4543217422057779"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
    "    accuracy = 0  \n",
    "    y_hats = []\n",
    "    for tweet in test_x:\n",
    "        if naive_bayes_predict(tweet, logprior, loglikelihood) > 0:\n",
    "            y_hat_i = 1\n",
    "        else:\n",
    "            y_hat_i = 0\n",
    "\n",
    "        y_hats.append(y_hat_i)\n",
    "\n",
    "    error = np.mean(np.absolute(y_hats-test_y))\n",
    "    accuracy = 1-error\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7767200346170489"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_naive_bayes(validation_nb.texto_normalizado, validation_nb.sentimiento, logprior, loglikelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_95829/2613921363.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_nb['prediccion'] = validation_nb.texto_normalizado.apply(lambda x: 1 if naive_bayes_predict(x, logprior, loglikelihood) > 0 else 0)\n"
     ]
    }
   ],
   "source": [
    "validation_nb['prediccion'] = validation_nb.texto_normalizado.apply(lambda x: 1 if naive_bayes_predict(x, logprior, loglikelihood) > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_95829/2476832433.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_nb['puntaje'] = validation_nb.texto_normalizado.apply(lambda x: naive_bayes_predict(x, logprior, loglikelihood))\n"
     ]
    }
   ],
   "source": [
    "validation_nb['puntaje'] = validation_nb.texto_normalizado.apply(lambda x: naive_bayes_predict(x, logprior, loglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>texto_normalizado</th>\n",
       "      <th>prediccion</th>\n",
       "      <th>puntaje</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7450</td>\n",
       "      <td>@marianorajoy Estamos muy satisfechos</td>\n",
       "      <td>1</td>\n",
       "      <td>satisfecho</td>\n",
       "      <td>1</td>\n",
       "      <td>0.729572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1332</td>\n",
       "      <td>Nada mejor que pasar la navidad con la familia...</td>\n",
       "      <td>1</td>\n",
       "      <td>mejor pasar navidad familia amigo uds pasar</td>\n",
       "      <td>1</td>\n",
       "      <td>3.391953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6436</td>\n",
       "      <td>Planeta creativo: nuevo placer otra interesant...</td>\n",
       "      <td>1</td>\n",
       "      <td>planeta creativo nuevo placer interesante jorn...</td>\n",
       "      <td>1</td>\n",
       "      <td>7.864978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8973</td>\n",
       "      <td>Necesito ir a mi hogar y dormir con mis dos hi...</td>\n",
       "      <td>0</td>\n",
       "      <td>necesitar ir hogar dormir dos hijo peludos kab...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.473601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>803</td>\n",
       "      <td>En la XII edición Premios Culturas de Extremad...</td>\n",
       "      <td>1</td>\n",
       "      <td>xii edicion premio culturas extremadura galard...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.551393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>8116</td>\n",
       "      <td>@nataliaprzc Con Liberación se vive mejor</td>\n",
       "      <td>1</td>\n",
       "      <td>liberacion vivir mejor</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.255210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3409</th>\n",
       "      <td>15367</td>\n",
       "      <td>Bajando a Calahorra ya no queda nada para el c...</td>\n",
       "      <td>1</td>\n",
       "      <td>bajar calahorra quedar cambio junto salir adel...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.081062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410</th>\n",
       "      <td>10591</td>\n",
       "      <td>Es que estos dolores, son bárbaros...</td>\n",
       "      <td>0</td>\n",
       "      <td>dolor barbaros</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.043017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3411</th>\n",
       "      <td>2111</td>\n",
       "      <td>#ChacónenLaSER : \"Me siento con capacidad y co...</td>\n",
       "      <td>1</td>\n",
       "      <td>chaconenlaser sentar capacidad equipo superman...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.208470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>13242</td>\n",
       "      <td>Por que existe gente bruta !!! Que cuando ven ...</td>\n",
       "      <td>0</td>\n",
       "      <td>exir gente bruta venir zapatilla nuevo pisar p...</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.649833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2311 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              texto  \\\n",
       "0           7450             @marianorajoy Estamos muy satisfechos    \n",
       "1           1332  Nada mejor que pasar la navidad con la familia...   \n",
       "2           6436  Planeta creativo: nuevo placer otra interesant...   \n",
       "3           8973  Necesito ir a mi hogar y dormir con mis dos hi...   \n",
       "4            803  En la XII edición Premios Culturas de Extremad...   \n",
       "...          ...                                                ...   \n",
       "3408        8116          @nataliaprzc Con Liberación se vive mejor   \n",
       "3409       15367  Bajando a Calahorra ya no queda nada para el c...   \n",
       "3410       10591              Es que estos dolores, son bárbaros...   \n",
       "3411        2111  #ChacónenLaSER : \"Me siento con capacidad y co...   \n",
       "3413       13242  Por que existe gente bruta !!! Que cuando ven ...   \n",
       "\n",
       "      sentimiento                                  texto_normalizado  \\\n",
       "0               1                                         satisfecho   \n",
       "1               1        mejor pasar navidad familia amigo uds pasar   \n",
       "2               1  planeta creativo nuevo placer interesante jorn...   \n",
       "3               0  necesitar ir hogar dormir dos hijo peludos kab...   \n",
       "4               1  xii edicion premio culturas extremadura galard...   \n",
       "...           ...                                                ...   \n",
       "3408            1                             liberacion vivir mejor   \n",
       "3409            1  bajar calahorra quedar cambio junto salir adel...   \n",
       "3410            0                                     dolor barbaros   \n",
       "3411            1  chaconenlaser sentar capacidad equipo superman...   \n",
       "3413            0  exir gente bruta venir zapatilla nuevo pisar p...   \n",
       "\n",
       "      prediccion   puntaje  \n",
       "0              1  0.729572  \n",
       "1              1  3.391953  \n",
       "2              1  7.864978  \n",
       "3              0 -1.473601  \n",
       "4              1  5.551393  \n",
       "...          ...       ...  \n",
       "3408           0 -0.255210  \n",
       "3409           1  2.081062  \n",
       "3410           0 -2.043017  \n",
       "3411           1  0.208470  \n",
       "3413           0 -4.649833  \n",
       "\n",
       "[2311 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1795"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_nb[validation_nb['sentimiento'] == validation_nb['prediccion']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[926 256]\n",
      " [260 869]]\n",
      "Precision: [0.78077572 0.77244444]\n",
      "Recall: [0.78341794 0.76970771]\n",
      "Accuracy: 0.7767200346170489\n",
      "F1 Score: [0.78209459 0.77107365]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cm = confusion_matrix(validation_nb['sentimiento'], validation_nb['prediccion'])\n",
    "\n",
    "precision = precision_score(validation_nb['sentimiento'], validation_nb['prediccion'], average=None)\n",
    "recall = recall_score(validation_nb['sentimiento'], validation_nb['prediccion'], average=None)\n",
    "accuracy = accuracy_score(validation_nb['sentimiento'], validation_nb['prediccion'])\n",
    "\n",
    "f1 = f1_score(validation_nb['sentimiento'], validation_nb['prediccion'], average=None)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
