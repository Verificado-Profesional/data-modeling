{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96047/1787946145.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('processed_tweets_stemm/train.csv')\n",
    "validation = pd.read_csv('processed_tweets_stemm/validation.csv')\n",
    "test = pd.read_csv('processed_tweets_stemm/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.rename(columns={'texto_procesado': 'texto_normalizado'}, inplace=True)\n",
    "validation.rename(columns={'texto_procesado': 'texto_normalizado'}, inplace=True)\n",
    "test.rename(columns={'texto_procesado': 'texto_normalizado'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(subset=['texto_normalizado'], inplace=True)\n",
    "validation.dropna(subset=['texto_normalizado'], inplace=True)\n",
    "test.dropna(subset=['texto_normalizado'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conteo_palabras(tweets):\n",
    "    conteo_palabras = defaultdict(int)\n",
    "\n",
    "    for tweet in tweets:\n",
    "        tokens = word_tokenize(tweet)\n",
    "\n",
    "        for token in tokens:\n",
    "            conteo_palabras[token] += 1\n",
    "    \n",
    "    return conteo_palabras\n",
    "\n",
    "conteo_palabras_positivas = conteo_palabras(train[train['sentimiento'] == 2]['texto_normalizado'])\n",
    "\n",
    "conteo_palabras_negativas = conteo_palabras(train[train['sentimiento'] == 1]['texto_normalizado'])\n",
    "\n",
    "conteo_palabras_neutrales = conteo_palabras(train[train['sentimiento'] == 0]['texto_normalizado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'virgen\",\n",
       " \"'vad\",\n",
       " \"'suscripcion\",\n",
       " \"'creador\",\n",
       " \"'liderazg\",\n",
       " \"'chul\",\n",
       " \"'aranjuez\",\n",
       " \"'membret\",\n",
       " \"'boletin\",\n",
       " \"'exprim\",\n",
       " \"'ucid\",\n",
       " \"'enrer\",\n",
       " \"'to2\",\n",
       " \"'nomequeriadespert\",\n",
       " \"'pais.y\",\n",
       " \"'desus\",\n",
       " \"'antoni\",\n",
       " \"'reviv\",\n",
       " \"'ultim\",\n",
       " \"'beats\",\n",
       " \"'garch\",\n",
       " \"'publicit\",\n",
       " \"'empiez\",\n",
       " \"'division\",\n",
       " \"'ascazonivelmaxim\",\n",
       " \"'ahahahahah\",\n",
       " \"'merend\",\n",
       " \"'descoloc\",\n",
       " \"'virtud\",\n",
       " \"'baratit\",\n",
       " \"'sism\",\n",
       " \"'delvpt\",\n",
       " \"'buchisap\",\n",
       " \"'roqy\",\n",
       " \"'determin\",\n",
       " \"'conflict\",\n",
       " \"'sobrecog\",\n",
       " \"'estrell\",\n",
       " \"'20h.act\",\n",
       " \"'resum\",\n",
       " \"'literal\",\n",
       " \"'gordeon\",\n",
       " \"'taz\",\n",
       " \"'nervi\",\n",
       " \"'soseurop\",\n",
       " \"'anteproyect\",\n",
       " \"'extend\",\n",
       " \"'lissavetzky\",\n",
       " \"'llor\",\n",
       " \"'fueg\",\n",
       " \"'nell\",\n",
       " \"'cameron\",\n",
       " \"'supend\",\n",
       " \"'silmarillion\",\n",
       " \"'norz\",\n",
       " '0-0',\n",
       " \"'29m\",\n",
       " \"'acos\",\n",
       " \"'marisc\",\n",
       " \"'chel\",\n",
       " \"'barc\",\n",
       " \"'krat\",\n",
       " \"'curi\",\n",
       " \"'chever\",\n",
       " \"'oracul\",\n",
       " \"'robert\",\n",
       " \"'amor\",\n",
       " \"'city\",\n",
       " \"'trimestr\",\n",
       " \"'enhorabuena\",\n",
       " \"'materializ\",\n",
       " \"'mucha\",\n",
       " \"'mu\",\n",
       " \"'moller\",\n",
       " \"'precios\",\n",
       " \"'taan\",\n",
       " \"'norteamerican\",\n",
       " \"'hormiguer\",\n",
       " \"'sinverg√ºenz\",\n",
       " \"'vison\",\n",
       " \"'calla\",\n",
       " \"'carapulcr\",\n",
       " \"'arrech\",\n",
       " \"'copi\",\n",
       " \"'dem√†\",\n",
       " \"'analfabet\",\n",
       " \"'soled\",\n",
       " \"'apremi\",\n",
       " \"'oficiosamernt\",\n",
       " \"'fnac\",\n",
       " \"'krisbell\",\n",
       " \"'cumplea√±\",\n",
       " \"'programapp\",\n",
       " \"'lind\",\n",
       " \"'menudiari\",\n",
       " \"'joel\",\n",
       " \"'fanart\",\n",
       " \"'acog\",\n",
       " \"'sprint\",\n",
       " \"'forb\",\n",
       " \"'cuch\",\n",
       " \"'tuelig\",\n",
       " 'jfernandezarc',\n",
       " \"'aragones\",\n",
       " \"'awww\",\n",
       " \"'discotec\",\n",
       " \"'period\",\n",
       " \"'cinemex\",\n",
       " \"'economics\",\n",
       " \"'viernesconromin\",\n",
       " \"'socialism\",\n",
       " \"'mitic\",\n",
       " \"'arbol\",\n",
       " \"'feofe\",\n",
       " \"'descend\",\n",
       " \"'frecuent\",\n",
       " \"'yog\",\n",
       " 'j',\n",
       " \"'cubano.est\",\n",
       " \"'complic\",\n",
       " \"'15:30\",\n",
       " \"'insaci\",\n",
       " \"'11\",\n",
       " \"'exager\",\n",
       " \"'mint\",\n",
       " \"'misms\",\n",
       " \"'reaccion\",\n",
       " \"'multicolor\",\n",
       " \"'_ten\",\n",
       " \"'dandoll\",\n",
       " \"'‚úä\",\n",
       " \"'110a√±osdeleyend\",\n",
       " \"'guipuzcoan\",\n",
       " \"'bienven\",\n",
       " \"'avil\",\n",
       " \"'antiip\",\n",
       " \"'sobri\",\n",
       " \"'ando\",\n",
       " \"'asfalt\",\n",
       " \"'19\",\n",
       " \"'inq\",\n",
       " \"'clasifiqu\",\n",
       " \"'leem\",\n",
       " \"'laconstitucionquenosun\",\n",
       " \"'gri√±anmient\",\n",
       " \"'normal\",\n",
       " \"'defraud\",\n",
       " \"'2014\",\n",
       " \"'potasi\",\n",
       " \"'lle\",\n",
       " \"'lentill\",\n",
       " \"'oftalmolog\",\n",
       " \"'verg\",\n",
       " \"'suicidi\",\n",
       " \"'vej\",\n",
       " \"'535\",\n",
       " \"'putaa\",\n",
       " \"'stefani\",\n",
       " \"'rayoyenlas\",\n",
       " \"'minoritari\",\n",
       " \"'holand\",\n",
       " \"'elpaywall\",\n",
       " \"'millones.vari\",\n",
       " \"'evor\",\n",
       " \"'dictadur\",\n",
       " \"'pcs\",\n",
       " \"'dragon\",\n",
       " \"'bueeen\",\n",
       " \"'dunning-krug\",\n",
       " \"'oportunitat\",\n",
       " \"'maz\",\n",
       " \"'ajjajajajajajajaj\",\n",
       " \"'eurobon\",\n",
       " \"'ceim\",\n",
       " \"'bendic\",\n",
       " \"'cak\",\n",
       " \"'sepes\",\n",
       " \"'bachat\",\n",
       " \"'obsesion\",\n",
       " \"'feriant\",\n",
       " \"'bastay\",\n",
       " \"'vig\",\n",
       " \"'debatertv\",\n",
       " \"'ukai\",\n",
       " \"'eras\",\n",
       " \"'anticip\",\n",
       " \"'exclusion\",\n",
       " \"'mixt\",\n",
       " \"'haz\",\n",
       " \"'palaci\",\n",
       " \"'semanal\",\n",
       " \"'deliri\",\n",
       " \"'illinois\",\n",
       " \"'abrazott\",\n",
       " \"'lunch\",\n",
       " \"'recort\",\n",
       " \"'irak.segund\",\n",
       " \"'caraamapolaon\",\n",
       " \"'b16\",\n",
       " \"'apunt\",\n",
       " \"'sangrient\",\n",
       " \"'600\",\n",
       " \"'reinici\",\n",
       " \"'yu\",\n",
       " \"'wen\",\n",
       " \"'sazon\",\n",
       " \"'picadur\",\n",
       " \"'vision\",\n",
       " \"'lejit\",\n",
       " \"'sebasti\",\n",
       " \"'brice√±\",\n",
       " \"'anteoj\",\n",
       " \"'cataluny\",\n",
       " \"'esplendor\",\n",
       " \"'turqu\",\n",
       " \"'asamble\",\n",
       " \"'xabi\",\n",
       " \"'maquill\",\n",
       " \"'esperar\",\n",
       " \"'disturbi\",\n",
       " \"'enlac\",\n",
       " \"'regal\",\n",
       " \"'viej\",\n",
       " \"'gentequenocog\",\n",
       " \"'doctor\",\n",
       " \"'limon\",\n",
       " \"'ejecu\",\n",
       " \"'fiabl\",\n",
       " \"'pxc\",\n",
       " \"'nomelopierd\",\n",
       " \"'persistent\",\n",
       " \"'autografi\",\n",
       " \"'60\",\n",
       " \"'elit\",\n",
       " \"'casit\",\n",
       " \"'ydicendefenderderech\",\n",
       " \"'propied\",\n",
       " \"'qe\",\n",
       " \"'johns\",\n",
       " \"'esenci\",\n",
       " \"'cruc\",\n",
       " \"'muuuy\",\n",
       " \"'repasit\",\n",
       " \"'muchoo\",\n",
       " \"'indecis\",\n",
       " \"'cristian\",\n",
       " \"'facilisim\",\n",
       " \"'dylan\",\n",
       " \"'constanci\",\n",
       " \"'videoclub\",\n",
       " \"'loew\",\n",
       " \"'baz\",\n",
       " \"'savat\",\n",
       " \"'upyd-guadarram\",\n",
       " \"'libertaddigital.com/nacional/2011-‚Ä¶\",\n",
       " \"'reventaor\",\n",
       " \"'nicaragu\",\n",
       " \"'encuest\",\n",
       " \"'sonreir\",\n",
       " \"'afectu\",\n",
       " \"'vendras\",\n",
       " \"'ppc\",\n",
       " \"'desped\",\n",
       " \"'carin\",\n",
       " \"'abd\",\n",
       " \"'hund\",\n",
       " \"'din\",\n",
       " \"'mail\",\n",
       " \"'artilleri\",\n",
       " \"'gallardon\",\n",
       " \"'ete\",\n",
       " \"'invit\",\n",
       " \"'post-unchart\",\n",
       " \"'as-ti-lle-r\",\n",
       " \"'rectif\",\n",
       " \"'zanj\",\n",
       " \"'pull\",\n",
       " \"'griss\",\n",
       " \"'figueruel\",\n",
       " \"'fond\",\n",
       " \"'energ\",\n",
       " \"'erre\",\n",
       " \"'cahuit\",\n",
       " \"'primarin\",\n",
       " '1.500',\n",
       " \"'deterior\",\n",
       " \"'ruman\",\n",
       " \"'villal\",\n",
       " \"'maestrosquetuv\",\n",
       " \"'feligres\",\n",
       " \"'introduccion\",\n",
       " \"'itiner\",\n",
       " \"'felizmiercol\",\n",
       " \"'filolog\",\n",
       " \"'tres\",\n",
       " \"'twitteroff\",\n",
       " \"'recurr\",\n",
       " \"'intencion\",\n",
       " \"'favs\",\n",
       " \"'oo\",\n",
       " \"'pregon\",\n",
       " \"'demostrar\",\n",
       " \"'catedrat\",\n",
       " \"'syndicat\",\n",
       " \"'chibol\",\n",
       " \"'9am\",\n",
       " \"'contamin\",\n",
       " \"'askalvarogang\",\n",
       " \"'ahno\",\n",
       " \"'interrump\",\n",
       " \"'eleg\",\n",
       " \"'plour\",\n",
       " \"'aren\",\n",
       " \"'cadav\",\n",
       " \"'videoya√±ez\",\n",
       " \"'naomi\",\n",
       " \"'prox\",\n",
       " \"'archiv\",\n",
       " \"'haiti\",\n",
       " 'annabosch',\n",
       " \"'dandom\",\n",
       " \"'carguit\",\n",
       " \"'celebr\",\n",
       " \"'empuj\",\n",
       " \"'chav\",\n",
       " \"'cuerd\",\n",
       " \"'fer\",\n",
       " \"'peset\",\n",
       " \"'dic\",\n",
       " \"'debilit\",\n",
       " \"'gordit\",\n",
       " \"'miseri\",\n",
       " \"'happyjungkookday\",\n",
       " \"'minorityreport\",\n",
       " \"'ranch\",\n",
       " \"'quiet\",\n",
       " \"'reirs\",\n",
       " \"'licor\",\n",
       " \"'mostrat\",\n",
       " \"'prat\",\n",
       " \"'vibr\",\n",
       " \"'convenc\",\n",
       " \"'agust\",\n",
       " \"'res\",\n",
       " \"'flacur\",\n",
       " \"'mty\",\n",
       " \"'amamant\",\n",
       " \"'noch\",\n",
       " \"'dadm\",\n",
       " \"'vueltecill\",\n",
       " \"'colabor\",\n",
       " \"'obrer\",\n",
       " \"'vaci\",\n",
       " \"'ufc\",\n",
       " \"'mgw\",\n",
       " \"'sancoch\",\n",
       " \"'psoe-iu\",\n",
       " \"'reaf\",\n",
       " \"'net\",\n",
       " \"'mejican\",\n",
       " \"'ida\",\n",
       " \"'electromagnet\",\n",
       " \"'minuci\",\n",
       " \"'marratx\",\n",
       " \"'rebr\",\n",
       " \"'dennis\",\n",
       " \"'enpez\",\n",
       " \"'reconduc\",\n",
       " \"'martadelcastill\",\n",
       " \"'itesm\",\n",
       " \"'lorc\",\n",
       " \"'juanm\",\n",
       " \"'nocheviej\",\n",
       " \"'vic\",\n",
       " \"'autoestim\",\n",
       " \"'columbi\",\n",
       " \"'oigofanat\",\n",
       " \"'worth\",\n",
       " \"'s3\",\n",
       " \"'qel\",\n",
       " \"'entidad\",\n",
       " \"'ashton\",\n",
       " \"'retras\",\n",
       " '3:23',\n",
       " \"'csif\",\n",
       " \"'langui\",\n",
       " \"'globalch\",\n",
       " \"'contitucional\",\n",
       " \"'impacient\",\n",
       " \"'ibf\",\n",
       " \"'great\",\n",
       " \"'comenzar\",\n",
       " \"'degener\",\n",
       " \"'cualqu\",\n",
       " \"'nav\",\n",
       " \"'mismisim\",\n",
       " 'hyundai',\n",
       " \"'amargur\",\n",
       " \"'grans\",\n",
       " \"'oswar\",\n",
       " \"'ho\",\n",
       " \"'cons\",\n",
       " \"'once\",\n",
       " \"'diabl\",\n",
       " \"'langost\",\n",
       " \"'investidur\",\n",
       " \"'panz\",\n",
       " \"'schmitz\",\n",
       " \"'regl\",\n",
       " \"'ü§ò\",\n",
       " \"'insol\",\n",
       " \"'desmantel\",\n",
       " \"'zaragoz\",\n",
       " \"'carteler\",\n",
       " \"'sagunt\",\n",
       " \"'realiz\",\n",
       " \"'masculin\",\n",
       " \"'municipal\",\n",
       " \"'gui√±ol\",\n",
       " \"'santfeliu\",\n",
       " \"'kofi\",\n",
       " \"'terrestr\",\n",
       " \"'crem\",\n",
       " \"'donald\",\n",
       " \"'amistad\",\n",
       " \"'gustart\",\n",
       " '7.15',\n",
       " \"'contrari\",\n",
       " \"'lahoradelplanet\",\n",
       " \"'alv\",\n",
       " \"'inaudit\",\n",
       " \"'intendent\",\n",
       " \"'comprot\",\n",
       " \"'dormitori\",\n",
       " \"'campanari\",\n",
       " \"'uedil\",\n",
       " \"'huel\",\n",
       " \"'nobl\",\n",
       " \"'acamp\",\n",
       " \"'80.000\",\n",
       " \"'ochenter\",\n",
       " \"'conden\",\n",
       " \"'besaz\",\n",
       " \"'elud\",\n",
       " \"'washington\",\n",
       " \"'dens\",\n",
       " \"'hereu\",\n",
       " \"'ric\",\n",
       " \"'emot\",\n",
       " \"'toky\",\n",
       " \"'calientit\",\n",
       " \"'forestal\",\n",
       " \"'vehicul\",\n",
       " \"'hond\",\n",
       " \"'gratis\",\n",
       " \"'carrill\",\n",
       " \"'clam\",\n",
       " \"'haza√±\",\n",
       " \"'i√±ig\",\n",
       " \"'abril\",\n",
       " \"'espan\",\n",
       " \"'a15\",\n",
       " \"'abrirl\",\n",
       " \"'peas\",\n",
       " \"'gand\",\n",
       " \"'balaz\",\n",
       " \"'insercion\",\n",
       " \"'mbcfw\",\n",
       " \"'manifesyt\",\n",
       " \"'sql\",\n",
       " \"'delic\",\n",
       " \"'rebeld\",\n",
       " \"'martial\",\n",
       " \"'dependient\",\n",
       " \"'miguel\",\n",
       " \"'enfermed\",\n",
       " \"'rhine-westphali\",\n",
       " \"'comet\",\n",
       " \"'taleb\",\n",
       " \"'minimiz\",\n",
       " \"'asistent\",\n",
       " \"'renuev\",\n",
       " \"'cientif\",\n",
       " \"'jejejej\",\n",
       " \"'compa√±\",\n",
       " \"'vallec\",\n",
       " \"'50mil\",\n",
       " \"'aizoon\",\n",
       " \"'model\",\n",
       " \"'manan\",\n",
       " \"'pulmon\",\n",
       " \"'bryan\",\n",
       " \"'trip\",\n",
       " \"'entrab\",\n",
       " \"'uuuuyyy\",\n",
       " \"'desesp\",\n",
       " \"'canton\",\n",
       " \"'ciudsdan\",\n",
       " \"'discograf\",\n",
       " \"'justific\",\n",
       " \"'botincraci\",\n",
       " \"'jos\",\n",
       " \"'u√±as\",\n",
       " '2,15',\n",
       " \"'plant\",\n",
       " \"'medianoch\",\n",
       " \"'abstuv\",\n",
       " \"'enchuf\",\n",
       " \"'trump\",\n",
       " \"'mient\",\n",
       " \"'unidireccional\",\n",
       " \"'feber\",\n",
       " \"'embarg\",\n",
       " \"'rueg\",\n",
       " \"'72m\",\n",
       " \"'brucewillis\",\n",
       " \"'cert\",\n",
       " \"'hacel\",\n",
       " \"'previs\",\n",
       " \"'lips\",\n",
       " \"'vota\",\n",
       " \"'matais\",\n",
       " \"'2tes\",\n",
       " \"'wyomings\",\n",
       " \"'panic\",\n",
       " \"'jolp\",\n",
       " \"'rosal\",\n",
       " \"'eurozon\",\n",
       " \"'san\",\n",
       " \"'liaran\",\n",
       " \"'calendari\",\n",
       " \"'920\",\n",
       " \"'hijobell\",\n",
       " \"'too\",\n",
       " \"'eh\",\n",
       " \"'trichet\",\n",
       " \"'maxim\",\n",
       " \"'trabajar.rbcb\",\n",
       " \"'fatim\",\n",
       " \"'stop\",\n",
       " \"'desinfl\",\n",
       " \"'gall\",\n",
       " \"'implic\",\n",
       " \"'rottweil\",\n",
       " \"'traj\",\n",
       " \"'desterr\",\n",
       " \"'frent\",\n",
       " \"'darsel\",\n",
       " \"'opaa\",\n",
       " \"'human\",\n",
       " \"'360.000\",\n",
       " \"'unfollow\",\n",
       " \"'15o\",\n",
       " \"'muller\",\n",
       " \"'catal√†\",\n",
       " \"'blank\",\n",
       " \"'diferencial\",\n",
       " \"'abstencion\",\n",
       " \"'followers\",\n",
       " \"'smp\",\n",
       " \"'socialmedi\",\n",
       " \"'sorpres\",\n",
       " \"'alete\",\n",
       " \"'concentr\",\n",
       " \"'tomacomentariofutboler\",\n",
       " \"'psdta\",\n",
       " 'princess',\n",
       " \"'grinan\",\n",
       " \"'vid\",\n",
       " \"'melill\",\n",
       " \"'constru\",\n",
       " \"'presidencial\",\n",
       " \"'afhletic\",\n",
       " \"'mason\",\n",
       " \"'clearest\",\n",
       " \"'fructifer\",\n",
       " \"'falang\",\n",
       " \"'juegaz\",\n",
       " \"'siii\",\n",
       " \"'faceamig\",\n",
       " \"'elvir\",\n",
       " \"'fiscaliz\",\n",
       " \"'3g\",\n",
       " \"'mandari\",\n",
       " \"'condicion\",\n",
       " \"'dhondt\",\n",
       " \"'portavoz\",\n",
       " \"'exhaust\",\n",
       " \"'reuters\",\n",
       " \"'batuec\",\n",
       " \"'royc\",\n",
       " \"'delux\",\n",
       " \"'hebre\",\n",
       " \"'atlet\",\n",
       " \"'consent\",\n",
       " \"'vol\",\n",
       " \"'gregori\",\n",
       " \"'escan\",\n",
       " \"'sra\",\n",
       " \"'huevin\",\n",
       " \"'banquer\",\n",
       " \"'cofradiasmlg\",\n",
       " \"'psiquiatr\",\n",
       " \"'cort\",\n",
       " \"'jonaler\",\n",
       " '2',\n",
       " \"'rat\",\n",
       " \"'lehm\",\n",
       " \"'esparz\",\n",
       " \"'tonel\",\n",
       " \"'francfort\",\n",
       " \"'semafor\",\n",
       " \"'fuerteventur\",\n",
       " \"'pwc\",\n",
       " \"'dificil\",\n",
       " \"'iisrael\",\n",
       " \"'vay\",\n",
       " \"'gal\",\n",
       " \"'tira\",\n",
       " \"'hahahah\",\n",
       " \"'retir\",\n",
       " \"'huell\",\n",
       " \"'dial\",\n",
       " \"'gatopard\",\n",
       " \"'recompens\",\n",
       " \"'murcielag\",\n",
       " \"'urg\",\n",
       " \"'empezais\",\n",
       " \"'per\",\n",
       " \"'minusval\",\n",
       " \"'se√±orasmayoresdegir\",\n",
       " \"'aliment\",\n",
       " 'vo',\n",
       " \"'hermand\",\n",
       " \"'juaasss\",\n",
       " \"'dio\",\n",
       " \"'roscon\",\n",
       " \"n't\",\n",
       " \"'sainet\",\n",
       " \"'intoc\",\n",
       " \"'72\",\n",
       " \"'llos\",\n",
       " \"'sembr\",\n",
       " \"'apreton\",\n",
       " \"'piquer\",\n",
       " \"'horror\",\n",
       " \"'marseill\",\n",
       " \"'vlog\",\n",
       " \"'conveni\",\n",
       " \"'adan\",\n",
       " \"'reestructur\",\n",
       " \"'cardi\",\n",
       " \"'500\",\n",
       " \"'palabrot\",\n",
       " \"'discurs\",\n",
       " \"'piqu\",\n",
       " \"'iesecampa√±\",\n",
       " \"'700\",\n",
       " \"'sistematiz\",\n",
       " '7,38',\n",
       " \"'fri\",\n",
       " \"'peopl\",\n",
       " \"'lol\",\n",
       " \"'jajajaj\",\n",
       " \"'mujer\",\n",
       " \"'2016\",\n",
       " \"'eje\",\n",
       " \"'apec\",\n",
       " \"'obvied\",\n",
       " \"'oper\",\n",
       " \"'canch\",\n",
       " \"'alt\",\n",
       " \"'brutal\",\n",
       " \"'breaking\",\n",
       " \"'temblorcr\",\n",
       " \"'priorat\",\n",
       " \"'soport\",\n",
       " \"'alej\",\n",
       " \"'talk\",\n",
       " \"'√±at\",\n",
       " \"'liiist\",\n",
       " \"'cuchill\",\n",
       " \"'expert\",\n",
       " \"'siend\",\n",
       " \"'coron\",\n",
       " \"'cerdany\",\n",
       " \"'play\",\n",
       " \"'paisaj\",\n",
       " \"'andes\",\n",
       " \"'roldan\",\n",
       " \"'18h\",\n",
       " \"'grumpycat\",\n",
       " '(',\n",
       " \"'fest\",\n",
       " \"'tormentaa\",\n",
       " \"'bros\",\n",
       " \"'enterr\",\n",
       " \"'135\",\n",
       " \"'palmill\",\n",
       " \"'vergonz\",\n",
       " \"'enhorabuen\",\n",
       " \"'comunic\",\n",
       " \"'bolill\",\n",
       " \"'retroced\",\n",
       " \"'chicoss\",\n",
       " \"'ofi\",\n",
       " \"'djok\",\n",
       " \"'bueln\",\n",
       " \"'ni√±ez\",\n",
       " \"'bescans\",\n",
       " \"'choriz\",\n",
       " \"'enamor\",\n",
       " \"'palabr\",\n",
       " \"'gominol\",\n",
       " \"'3m\",\n",
       " \"'tristez\",\n",
       " \"'sar\",\n",
       " \"'g√ºer\",\n",
       " \"'darll\",\n",
       " \"'indecent\",\n",
       " \"'pensamient\",\n",
       " \"'exterior\",\n",
       " \"'pensas\",\n",
       " \"'au\",\n",
       " \"'ppcajab\",\n",
       " \"'desaloj\",\n",
       " \"'tipicasfrasesdeabuel\",\n",
       " \"'asedi\",\n",
       " \"'cuatr\",\n",
       " \"'extra√±\",\n",
       " \"'arrim\",\n",
       " \"'argu\",\n",
       " \"'98\",\n",
       " \"'deslumbr\",\n",
       " \"'river\",\n",
       " \"'21.000\",\n",
       " \"'correct\",\n",
       " \"'column\",\n",
       " \"'indign\",\n",
       " \"'manchest\",\n",
       " \"'dier\",\n",
       " \"'exdirector\",\n",
       " '8,3',\n",
       " \"'enelbernabeun\",\n",
       " \"'campa√±\",\n",
       " \"'tsunami\",\n",
       " \"'macdonald\",\n",
       " \"'pellot\",\n",
       " \"'surreal\",\n",
       " \"'seb\",\n",
       " \"'huert\",\n",
       " '1-2',\n",
       " \"'greci\",\n",
       " \"'vivalaconstitucion\",\n",
       " \"'felicitar\",\n",
       " \"'starwars\",\n",
       " \"'entren\",\n",
       " \"'dijous\",\n",
       " \"'usb\",\n",
       " \"'manch\",\n",
       " \"'20nvotorubalc\",\n",
       " \"'xtian\",\n",
       " \"'teson\",\n",
       " \"'magnus\",\n",
       " \"'years\",\n",
       " \"'palabrasa\",\n",
       " \"'quien\",\n",
       " \"'oligopoli\",\n",
       " \"'rentabil\",\n",
       " \"'despid\",\n",
       " \"'lepr\",\n",
       " \"'volvi\",\n",
       " \"'palet\",\n",
       " \"'auror\",\n",
       " \"'bot\",\n",
       " \"'vendedor\",\n",
       " \"'13h\",\n",
       " \"'tarifari\",\n",
       " \"'marianit\",\n",
       " \"'gutierrez\",\n",
       " \"'meand\",\n",
       " \"'playlist\",\n",
       " \"'cri\",\n",
       " \"'just\",\n",
       " \"'inneg\",\n",
       " \"'probablement\",\n",
       " \"'168\",\n",
       " \"'acapulc\",\n",
       " \"'chauuu\",\n",
       " \"'ele\",\n",
       " \"'etfelicitofill\",\n",
       " \"'polariz\",\n",
       " \"'graduacion\",\n",
       " \"'venezolan\",\n",
       " \"'=p\",\n",
       " \"'alient\",\n",
       " \"'caramelit\",\n",
       " \"'tapasc\",\n",
       " \"'ptm\",\n",
       " \"'sunglass\",\n",
       " \"'hol\",\n",
       " \"'cnn\",\n",
       " \"'alba√±il\",\n",
       " \"'diasrt\",\n",
       " \"'obses\",\n",
       " \"'investidurarajoy\",\n",
       " \"'by\",\n",
       " \"'invest\",\n",
       " \"'promocion\",\n",
       " \"'criteri\",\n",
       " \"'mikel\",\n",
       " \"'articul\",\n",
       " \"'alfa\",\n",
       " \"'planaz\",\n",
       " \"'desaprovech\",\n",
       " \"'imperfect\",\n",
       " \"'sobrepes\",\n",
       " \"'panorama.segur\",\n",
       " \"'colos\",\n",
       " \"'hard\",\n",
       " \"'besot\",\n",
       " \"'futur\",\n",
       " \"'proporcional\",\n",
       " \"'megaplaz\",\n",
       " \"'copon\",\n",
       " \"'marlask\",\n",
       " \"'quic\",\n",
       " \"'ps4\",\n",
       " \"'suel\",\n",
       " \"'dutard\",\n",
       " \"'acu√±\",\n",
       " \"'besoo\",\n",
       " \"'satisfaccion\",\n",
       " \"'flotador\",\n",
       " \"'insomn\",\n",
       " \"'earpods\",\n",
       " \"'suced\",\n",
       " \"'rt\",\n",
       " \"'consort\",\n",
       " \"'logro√±\",\n",
       " \"'caperucit\",\n",
       " \"'aid\",\n",
       " \"'dilem\",\n",
       " \"'pepevergent\",\n",
       " \"'europe\",\n",
       " \"'ee.uu\",\n",
       " \"'antig√ºedad\",\n",
       " \"'tiemp\",\n",
       " \"'teneis\",\n",
       " \"'rq\",\n",
       " \"'descarg\",\n",
       " \"'ahmadinej\",\n",
       " \"'op\",\n",
       " \"'pedros\",\n",
       " \"'2012\",\n",
       " \"'loq\",\n",
       " \"'emisor\",\n",
       " \"'arnich\",\n",
       " \"'√±o√±\",\n",
       " \"'muac\",\n",
       " \"'alcald\",\n",
       " \"'se√±ori\",\n",
       " \"'disfrutal\",\n",
       " \"'yovotoamarian\",\n",
       " \"'tenis\",\n",
       " \"'inacab\",\n",
       " \"'ifeb\",\n",
       " \"'todavi\",\n",
       " \"'dagarmy\",\n",
       " \"'export\",\n",
       " \"'telepp\",\n",
       " \"'solvenci\",\n",
       " \"'suscit\",\n",
       " \"'prueb\",\n",
       " \"'gilipoll\",\n",
       " \"'basic\",\n",
       " \"'actual\",\n",
       " \"'torremolin\",\n",
       " \"'loos\",\n",
       " \"'jornadasm\",\n",
       " \"'22h\",\n",
       " \"'agri\",\n",
       " \"'alin\",\n",
       " \"'ggn\",\n",
       " \"'portofin\",\n",
       " \"'puntit\",\n",
       " \"'18\",\n",
       " 'ys',\n",
       " \"'autoritar\",\n",
       " \"'hechounoszorr\",\n",
       " \"'aiii\",\n",
       " \"'39\",\n",
       " \"'particul\",\n",
       " \"'gym\",\n",
       " \"'prejuici\",\n",
       " \"'opin\",\n",
       " \"'remolon\",\n",
       " \"'disc\",\n",
       " \"'noslavanameterdobl\",\n",
       " \"'apuest\",\n",
       " \"'72.000\",\n",
       " \"'adquisicion\",\n",
       " \"'huir\",\n",
       " \"'mary\",\n",
       " \"'talent\",\n",
       " \"'bronquiolitis\",\n",
       " \"'mend\",\n",
       " \"'street\",\n",
       " \"'chal\",\n",
       " \"'tinkerbell\",\n",
       " \"'prodici\",\n",
       " \"'hagarr\",\n",
       " \"'amis\",\n",
       " \"'transit\",\n",
       " \"'drxa\",\n",
       " \"'escribis\",\n",
       " \"'xenomorf\",\n",
       " \"'einstein\",\n",
       " \"'echo\",\n",
       " \"'naa\",\n",
       " \"'asunt\",\n",
       " \"'pescador\",\n",
       " \"'endurec\",\n",
       " \"'mordaz\",\n",
       " \"'tequil\",\n",
       " \"'josu\",\n",
       " \"'platud\",\n",
       " \"'diumeng\",\n",
       " \"'gumball\",\n",
       " \"'rub\",\n",
       " \"'schettin\",\n",
       " \"'crimen\",\n",
       " \"'salamenc\",\n",
       " \"'showmatch\",\n",
       " \"'complet\",\n",
       " \"'roch\",\n",
       " \"'usi\",\n",
       " \"'ferm\",\n",
       " \"'pedot\",\n",
       " \"'formul\",\n",
       " \"'nadaa\",\n",
       " \"'cabrill\",\n",
       " \"'avarici\",\n",
       " \"'javi\",\n",
       " \"'ehh\",\n",
       " \"'habi\",\n",
       " \"'gar\",\n",
       " \"'cabecer\",\n",
       " \"'almorz\",\n",
       " \"'cnmig\",\n",
       " \"'paranoid\",\n",
       " \"'gc\",\n",
       " \"'conmigo.s\",\n",
       " \"'2012.los\",\n",
       " \"'1931\",\n",
       " \"'analic\",\n",
       " \"'paj\",\n",
       " \"'cartuj\",\n",
       " \"'lector\",\n",
       " \"'99\",\n",
       " \"'maig\",\n",
       " \"'102\",\n",
       " \"'acte\",\n",
       " '7.700',\n",
       " \"'atril\",\n",
       " \"'lascosascomoson\",\n",
       " \"'acord\",\n",
       " \"'conform\",\n",
       " \"'hondur\",\n",
       " \"'ciu-pp\",\n",
       " \"'perdonam\",\n",
       " \"'existent\",\n",
       " \"'audiovisual\",\n",
       " \"'fiel\",\n",
       " \"'maria-n\",\n",
       " \"'rompepapeletasen\",\n",
       " \"'¬•\",\n",
       " \"'quinu\",\n",
       " \"'palahniuk\",\n",
       " \"'euc\",\n",
       " \"'mou\",\n",
       " \"'auxili\",\n",
       " \"'castr\",\n",
       " \"'ratin\",\n",
       " \"'hermanit\",\n",
       " \"'fe-tribun\",\n",
       " \"'convalec\",\n",
       " \"'venezuel\",\n",
       " \"'olavarr\",\n",
       " \"'bss\",\n",
       " \"'aproxim\",\n",
       " \"'plis\",\n",
       " \"'sanitari\",\n",
       " \"'pueblesit\",\n",
       " \"'biling√º\",\n",
       " \"'mesetari\",\n",
       " \"'cracks\",\n",
       " \"'daniel\",\n",
       " \"'deduc\",\n",
       " \"'marshall.mientr\",\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palabras_set = set(conteo_palabras_positivas.keys()).union(set(conteo_palabras_negativas.keys()))\n",
    "palabras_set = palabras_set.union(set(conteo_palabras_neutrales.keys()))\n",
    "palabras_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tweets(tweets, ys):\n",
    "    result = {}\n",
    "\n",
    "    for y, tweet in zip(ys, tweets):\n",
    "        for word in word_tokenize(tweet):\n",
    "            pair = (word,y)\n",
    "\n",
    "            if pair in result:\n",
    "                result[pair] += 1\n",
    "\n",
    "            else:\n",
    "                result[pair] = 1\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(freqs, word, label):\n",
    "    n = 0  \n",
    "\n",
    "    pair = (word, label)\n",
    "    if (pair in freqs):\n",
    "        n = freqs[pair]\n",
    "\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes1(freqs, train_x, train_y):\n",
    "    loglikelihood_pos = {}\n",
    "    loglikelihood_neg = {}\n",
    "    loglikelihood_neu = {}\n",
    "\n",
    "    vocab = set([pair[0] for pair in freqs.keys()])\n",
    "    V = len(vocab)\n",
    "\n",
    "    N_pos = N_neg = N_neu = 0\n",
    "    for pair in freqs.keys():\n",
    "        if pair[1] == 2:\n",
    "            N_pos += freqs[pair]\n",
    "        elif pair[1] == 1:\n",
    "            N_neg += freqs[pair]\n",
    "        else:\n",
    "            N_neu += freqs[pair]\n",
    "    \n",
    "    logprior_pos = np.log(N_pos / (N_pos + N_neg + N_neu))\n",
    "    logprior_neg = np.log(N_neg / (N_pos + N_neg + N_neu))\n",
    "    logprior_neu = np.log(N_neu / (N_pos + N_neg + N_neu))\n",
    "\n",
    "    for word in vocab:\n",
    "        freq_pos =lookup(freqs,word,2)\n",
    "        freq_neg =lookup(freqs,word,1)\n",
    "        freq_neu =lookup(freqs,word,0)\n",
    "\n",
    "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
    "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
    "        p_w_neu = (freq_neu + 1) / (N_neu + V)\n",
    "\n",
    "        loglikelihood_pos[word] = np.log(p_w_pos) - np.log(p_w_neg + p_w_neu)\n",
    "        loglikelihood_neg[word] = np.log(p_w_neg) - np.log(p_w_pos + p_w_neu)\n",
    "        loglikelihood_neu[word] = np.log(p_w_neu) - np.log(p_w_pos + p_w_neg)\n",
    "\n",
    "\n",
    "    return loglikelihood_pos, loglikelihood_neg, loglikelihood_neu, logprior_pos, logprior_neg, logprior_neu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict1(tweet, logprior_pos, logprior_neg, logprior_neu, loglikelihood_pos,loglikelihood_neg, loglikelihood_neu):\n",
    "    word_l = word_tokenize(tweet)\n",
    "\n",
    "    p_pos = logprior_pos\n",
    "    p_neg = logprior_neg\n",
    "    p_neu = logprior_neu\n",
    "\n",
    "    for word in word_l:\n",
    "        if word in loglikelihood_pos:\n",
    "            p_pos += loglikelihood_pos[word]\n",
    "        if word in loglikelihood_neg:\n",
    "            p_neg += loglikelihood_neg[word]\n",
    "        if word in loglikelihood_neu:\n",
    "            p_neu += loglikelihood_neu[word]\n",
    "            \n",
    "    return {2: p_pos, 1: p_neg, 0: p_neu}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs1 = count_tweets(train.texto_normalizado, train.sentimiento)\n",
    "loglikelihood_pos, loglikelihood_neg, loglikelihood_neu, logprior_pos, logprior_neg, logprior_neu = train_naive_bayes1(freqs1, train.texto_normalizado, train.sentimiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation['prediccion'] = validation['texto_normalizado'].apply(lambda x: max(naive_bayes_predict1(x,logprior_pos, logprior_neg, logprior_neu, loglikelihood_pos,loglikelihood_neg, loglikelihood_neu), key=naive_bayes_predict1(x, logprior_pos, logprior_neg, logprior_neu, loglikelihood_pos,loglikelihood_neg, loglikelihood_neu).get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>texto_normalizado</th>\n",
       "      <th>prediccion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7450</td>\n",
       "      <td>@marianorajoy Estamos muy satisfechos</td>\n",
       "      <td>2</td>\n",
       "      <td>['satisfech']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1332</td>\n",
       "      <td>Nada mejor que pasar la navidad con la familia...</td>\n",
       "      <td>2</td>\n",
       "      <td>['mejor', 'pas', 'navid', 'famili', 'amig', 'u...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6436</td>\n",
       "      <td>Planeta creativo: nuevo placer otra interesant...</td>\n",
       "      <td>2</td>\n",
       "      <td>['planet', 'creativ', 'nuev', 'plac', 'interes...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8973</td>\n",
       "      <td>Necesito ir a mi hogar y dormir con mis dos hi...</td>\n",
       "      <td>1</td>\n",
       "      <td>['necesit', 'ir', 'hog', 'dorm', 'dos', 'hij',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>803</td>\n",
       "      <td>En la XII edici√≥n Premios Culturas de Extremad...</td>\n",
       "      <td>2</td>\n",
       "      <td>['xii', 'edicion', 'premi', 'cultur', 'extrema...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3409</th>\n",
       "      <td>15367</td>\n",
       "      <td>Bajando a Calahorra ya no queda nada para el c...</td>\n",
       "      <td>2</td>\n",
       "      <td>['baj', 'calahorr', 'qued', 'cambi', 'junt', '...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410</th>\n",
       "      <td>10591</td>\n",
       "      <td>Es que estos dolores, son b√°rbaros...</td>\n",
       "      <td>1</td>\n",
       "      <td>['dolor', 'barbar', '...']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3411</th>\n",
       "      <td>2111</td>\n",
       "      <td>#Chac√≥nenLaSER : \"Me siento con capacidad y co...</td>\n",
       "      <td>2</td>\n",
       "      <td>['chaconenlas', 'sient', 'capac', 'equip', 'su...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3412</th>\n",
       "      <td>14924</td>\n",
       "      <td>La Prima de Riesgo es 1 estafa de los Mercados...</td>\n",
       "      <td>0</td>\n",
       "      <td>['prim', 'riesg', '1', 'estaf', 'merc', 'bast'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>13242</td>\n",
       "      <td>Por que existe gente bruta !!! Que cuando ven ...</td>\n",
       "      <td>1</td>\n",
       "      <td>['exist', 'gent', 'brut', 'ven', 'zapatill', '...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3414 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              texto  \\\n",
       "0           7450             @marianorajoy Estamos muy satisfechos    \n",
       "1           1332  Nada mejor que pasar la navidad con la familia...   \n",
       "2           6436  Planeta creativo: nuevo placer otra interesant...   \n",
       "3           8973  Necesito ir a mi hogar y dormir con mis dos hi...   \n",
       "4            803  En la XII edici√≥n Premios Culturas de Extremad...   \n",
       "...          ...                                                ...   \n",
       "3409       15367  Bajando a Calahorra ya no queda nada para el c...   \n",
       "3410       10591              Es que estos dolores, son b√°rbaros...   \n",
       "3411        2111  #Chac√≥nenLaSER : \"Me siento con capacidad y co...   \n",
       "3412       14924  La Prima de Riesgo es 1 estafa de los Mercados...   \n",
       "3413       13242  Por que existe gente bruta !!! Que cuando ven ...   \n",
       "\n",
       "      sentimiento                                  texto_normalizado  \\\n",
       "0               2                                      ['satisfech']   \n",
       "1               2  ['mejor', 'pas', 'navid', 'famili', 'amig', 'u...   \n",
       "2               2  ['planet', 'creativ', 'nuev', 'plac', 'interes...   \n",
       "3               1  ['necesit', 'ir', 'hog', 'dorm', 'dos', 'hij',...   \n",
       "4               2  ['xii', 'edicion', 'premi', 'cultur', 'extrema...   \n",
       "...           ...                                                ...   \n",
       "3409            2  ['baj', 'calahorr', 'qued', 'cambi', 'junt', '...   \n",
       "3410            1                         ['dolor', 'barbar', '...']   \n",
       "3411            2  ['chaconenlas', 'sient', 'capac', 'equip', 'su...   \n",
       "3412            0  ['prim', 'riesg', '1', 'estaf', 'merc', 'bast'...   \n",
       "3413            1  ['exist', 'gent', 'brut', 'ven', 'zapatill', '...   \n",
       "\n",
       "      prediccion  \n",
       "0              0  \n",
       "1              2  \n",
       "2              2  \n",
       "3              1  \n",
       "4              2  \n",
       "...          ...  \n",
       "3409           0  \n",
       "3410           1  \n",
       "3411           1  \n",
       "3412           1  \n",
       "3413           1  \n",
       "\n",
       "[3414 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediccion\n",
       "1    808\n",
       "2    759\n",
       "0    397\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation[validation['sentimiento'] == validation['prediccion']].prediccion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentimiento\n",
       "0    704\n",
       "1    374\n",
       "2    372\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation[validation['sentimiento'] != validation['prediccion']].sentimiento.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[397 398 306]\n",
      " [219 808 155]\n",
      " [179 193 759]]\n",
      "Precision: [0.49937107 0.5775554  0.62213115]\n",
      "Recall: [0.36058129 0.68358714 0.67108753]\n",
      "Accuracy: 0.5752782659636789\n",
      "F1 Score: [0.41877637 0.62611391 0.64568269]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Matriz de confusi√≥n\n",
    "cm = confusion_matrix(validation['sentimiento'], validation['prediccion'])\n",
    "\n",
    "precision = precision_score(validation['sentimiento'], validation['prediccion'], average=None)\n",
    "recall = recall_score(validation['sentimiento'], validation['prediccion'], average=None)\n",
    "accuracy = accuracy_score(validation['sentimiento'], validation['prediccion'])\n",
    "\n",
    "f1 = f1_score(validation['sentimiento'], validation['prediccion'], average=None)\n",
    "\n",
    "print(\"Matriz de confusi√≥n:\")\n",
    "print(cm)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo sin neutrales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nb = train[train['sentimiento'] != 0]\n",
    "validation_nb = validation[validation['sentimiento'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96047/2834200813.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_nb['sentimiento'] = train_nb['sentimiento'].apply(lambda x: 1 if x == 2 else 0)\n",
      "/tmp/ipykernel_96047/2834200813.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_nb['sentimiento'] = validation_nb['sentimiento'].apply(lambda x: 1 if x == 2 else 0)\n"
     ]
    }
   ],
   "source": [
    "train_nb['sentimiento'] = train_nb['sentimiento'].apply(lambda x: 1 if x == 2 else 0)\n",
    "validation_nb['sentimiento'] = validation_nb['sentimiento'].apply(lambda x: 1 if x == 2 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>texto_normalizado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10221</td>\n",
       "      <td>@Manuellflorod Bienvenida (triste) realidad, a...</td>\n",
       "      <td>0</td>\n",
       "      <td>['bienven', 'trist', 'realid', 'andam', 'mism']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9565</td>\n",
       "      <td>Estar en los brazos de mi novio es lo √∫nico qu...</td>\n",
       "      <td>1</td>\n",
       "      <td>['braz', 'novi', 'unic', 'quier', 'necesit']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7713</td>\n",
       "      <td>@ahorapodemos @ierrejon Tambien que las empres...</td>\n",
       "      <td>1</td>\n",
       "      <td>['tambi', 'empres', 'independient', 'contact',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1038</td>\n",
       "      <td>El tono duro y sin concesiones de la r√©plica d...</td>\n",
       "      <td>0</td>\n",
       "      <td>['ton', 'dur', 'concesion', 'replic', 'rajoy',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>Bd√≠as. EM no se ira de puente. Si vosotros os ...</td>\n",
       "      <td>1</td>\n",
       "      <td>['bdi', 'em', 'ira', 'puent', 'si', 'vais', 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10236</th>\n",
       "      <td>11285</td>\n",
       "      <td>No, solo quiero bailarte la medusa loca en pri...</td>\n",
       "      <td>1</td>\n",
       "      <td>['sol', 'quier', 'bailart', 'medus', 'loc', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10237</th>\n",
       "      <td>11965</td>\n",
       "      <td>@cuervotinelli lo √∫nico que te puse fue que qu...</td>\n",
       "      <td>0</td>\n",
       "      <td>['unic', 'pus', 'quer', 'jug', 'lol', 'tortug'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10238</th>\n",
       "      <td>5390</td>\n",
       "      <td>La Audiencia Nacional condena a 20 a√±os de pri...</td>\n",
       "      <td>0</td>\n",
       "      <td>['audienci', 'nacional', 'conden', '20', 'a√±os...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10239</th>\n",
       "      <td>860</td>\n",
       "      <td>RT @eP_Titulares: #Sociedad Muere apu√±alada la...</td>\n",
       "      <td>0</td>\n",
       "      <td>['socied', 'muer', 'apu√±al', 'propietari', 'za...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10240</th>\n",
       "      <td>15796</td>\n",
       "      <td>. @UPyD una sanidad y educaci√≥n com√∫n y De cal...</td>\n",
       "      <td>1</td>\n",
       "      <td>['sanid', 'educ', 'comun', 'calid', 'espa√±ol',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6876 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              texto  \\\n",
       "0           10221  @Manuellflorod Bienvenida (triste) realidad, a...   \n",
       "1            9565  Estar en los brazos de mi novio es lo √∫nico qu...   \n",
       "3            7713  @ahorapodemos @ierrejon Tambien que las empres...   \n",
       "5            1038  El tono duro y sin concesiones de la r√©plica d...   \n",
       "7              10  Bd√≠as. EM no se ira de puente. Si vosotros os ...   \n",
       "...           ...                                                ...   \n",
       "10236       11285  No, solo quiero bailarte la medusa loca en pri...   \n",
       "10237       11965  @cuervotinelli lo √∫nico que te puse fue que qu...   \n",
       "10238        5390  La Audiencia Nacional condena a 20 a√±os de pri...   \n",
       "10239         860  RT @eP_Titulares: #Sociedad Muere apu√±alada la...   \n",
       "10240       15796  . @UPyD una sanidad y educaci√≥n com√∫n y De cal...   \n",
       "\n",
       "       sentimiento                                  texto_normalizado  \n",
       "0                0    ['bienven', 'trist', 'realid', 'andam', 'mism']  \n",
       "1                1       ['braz', 'novi', 'unic', 'quier', 'necesit']  \n",
       "3                1  ['tambi', 'empres', 'independient', 'contact',...  \n",
       "5                0  ['ton', 'dur', 'concesion', 'replic', 'rajoy',...  \n",
       "7                1  ['bdi', 'em', 'ira', 'puent', 'si', 'vais', 'd...  \n",
       "...            ...                                                ...  \n",
       "10236            1  ['sol', 'quier', 'bailart', 'medus', 'loc', 'p...  \n",
       "10237            0  ['unic', 'pus', 'quer', 'jug', 'lol', 'tortug'...  \n",
       "10238            0  ['audienci', 'nacional', 'conden', '20', 'a√±os...  \n",
       "10239            0  ['socied', 'muer', 'apu√±al', 'propietari', 'za...  \n",
       "10240            1  ['sanid', 'educ', 'comun', 'calid', 'espa√±ol',...  \n",
       "\n",
       "[6876 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup(freqs, word, label):\n",
    "    n = 0  \n",
    "\n",
    "    pair = (word, label)\n",
    "    if (pair in freqs):\n",
    "        n = freqs[pair]\n",
    "\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(freqs, train_x, train_y):\n",
    "    loglikelihood = {}\n",
    "    logprior = 0\n",
    "    vocab = palabras_set\n",
    "    V = len(vocab)\n",
    "    N_pos = N_neg = 0\n",
    "\n",
    "    for pair in freqs.keys():\n",
    "        if pair[1] > 0:\n",
    "            N_pos += freqs[pair]\n",
    "\n",
    "        else:\n",
    "            N_neg += freqs[pair]\n",
    "\n",
    "    D = len(train_y)\n",
    "    D_pos =np.sum(train_y)\n",
    "    D_neg = D-D_pos\n",
    "    logprior =np.log(D_pos) - np.log(D_neg)\n",
    "\n",
    "    for word in vocab:\n",
    "        freq_pos =lookup(freqs,word,1)\n",
    "        freq_neg =lookup(freqs,word,0)\n",
    "\n",
    "        p_w_pos = (freq_pos + 1) / (N_pos + V)\n",
    "        p_w_neg = (freq_neg + 1) / (N_neg + V)\n",
    "\n",
    "        loglikelihood[word] = np.log(p_w_pos/p_w_neg)\n",
    "\n",
    "\n",
    "    return logprior, loglikelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = count_tweets(train_nb.texto_normalizado, train_nb.sentimiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "logprior, loglikelihood = train_naive_bayes(freqs, train_nb.texto_normalizado, train_nb.sentimiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_predict(tweet, logprior, loglikelihood):\n",
    "    word_l = word_tokenize(tweet)\n",
    "    p = 0\n",
    "    p += logprior\n",
    "\n",
    "    for word in word_l:\n",
    "        if word in loglikelihood:\n",
    "            p += loglikelihood[word]\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tweet = 'pesimo horrible bueno hermoso'\n",
    "p = naive_bayes_predict(my_tweet, logprior, loglikelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.01163480256770022"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
    "    accuracy = 0 \n",
    "    y_hats = []\n",
    "    for tweet in test_x:\n",
    "        if naive_bayes_predict(tweet, logprior, loglikelihood) > 0:\n",
    "            y_hat_i = 1\n",
    "        else:\n",
    "            y_hat_i = 0\n",
    "\n",
    "        y_hats.append(y_hat_i)\n",
    "\n",
    "    error = np.mean(np.absolute(y_hats-test_y))\n",
    "    accuracy = 1-error\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7929096411586684"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_naive_bayes(validation_nb.texto_normalizado, validation_nb.sentimiento, logprior, loglikelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96047/2613921363.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_nb['prediccion'] = validation_nb.texto_normalizado.apply(lambda x: 1 if naive_bayes_predict(x, logprior, loglikelihood) > 0 else 0)\n"
     ]
    }
   ],
   "source": [
    "validation_nb['prediccion'] = validation_nb.texto_normalizado.apply(lambda x: 1 if naive_bayes_predict(x, logprior, loglikelihood) > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96047/2476832433.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_nb['puntaje'] = validation_nb.texto_normalizado.apply(lambda x: naive_bayes_predict(x, logprior, loglikelihood))\n"
     ]
    }
   ],
   "source": [
    "validation_nb['puntaje'] = validation_nb.texto_normalizado.apply(lambda x: naive_bayes_predict(x, logprior, loglikelihood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>texto_normalizado</th>\n",
       "      <th>prediccion</th>\n",
       "      <th>puntaje</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7450</td>\n",
       "      <td>@marianorajoy Estamos muy satisfechos</td>\n",
       "      <td>1</td>\n",
       "      <td>['satisfech']</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1332</td>\n",
       "      <td>Nada mejor que pasar la navidad con la familia...</td>\n",
       "      <td>1</td>\n",
       "      <td>['mejor', 'pas', 'navid', 'famili', 'amig', 'u...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.152403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6436</td>\n",
       "      <td>Planeta creativo: nuevo placer otra interesant...</td>\n",
       "      <td>1</td>\n",
       "      <td>['planet', 'creativ', 'nuev', 'plac', 'interes...</td>\n",
       "      <td>1</td>\n",
       "      <td>6.140234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8973</td>\n",
       "      <td>Necesito ir a mi hogar y dormir con mis dos hi...</td>\n",
       "      <td>0</td>\n",
       "      <td>['necesit', 'ir', 'hog', 'dorm', 'dos', 'hij',...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.191930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>803</td>\n",
       "      <td>En la XII edici√≥n Premios Culturas de Extremad...</td>\n",
       "      <td>1</td>\n",
       "      <td>['xii', 'edicion', 'premi', 'cultur', 'extrema...</td>\n",
       "      <td>1</td>\n",
       "      <td>5.416284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3408</th>\n",
       "      <td>8116</td>\n",
       "      <td>@nataliaprzc Con Liberaci√≥n se vive mejor</td>\n",
       "      <td>1</td>\n",
       "      <td>['liber', 'viv', 'mejor']</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.339169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3409</th>\n",
       "      <td>15367</td>\n",
       "      <td>Bajando a Calahorra ya no queda nada para el c...</td>\n",
       "      <td>1</td>\n",
       "      <td>['baj', 'calahorr', 'qued', 'cambi', 'junt', '...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.845549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3410</th>\n",
       "      <td>10591</td>\n",
       "      <td>Es que estos dolores, son b√°rbaros...</td>\n",
       "      <td>0</td>\n",
       "      <td>['dolor', 'barbar', '...']</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.061629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3411</th>\n",
       "      <td>2111</td>\n",
       "      <td>#Chac√≥nenLaSER : \"Me siento con capacidad y co...</td>\n",
       "      <td>1</td>\n",
       "      <td>['chaconenlas', 'sient', 'capac', 'equip', 'su...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.282432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>13242</td>\n",
       "      <td>Por que existe gente bruta !!! Que cuando ven ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['exist', 'gent', 'brut', 'ven', 'zapatill', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.042320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2313 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                              texto  \\\n",
       "0           7450             @marianorajoy Estamos muy satisfechos    \n",
       "1           1332  Nada mejor que pasar la navidad con la familia...   \n",
       "2           6436  Planeta creativo: nuevo placer otra interesant...   \n",
       "3           8973  Necesito ir a mi hogar y dormir con mis dos hi...   \n",
       "4            803  En la XII edici√≥n Premios Culturas de Extremad...   \n",
       "...          ...                                                ...   \n",
       "3408        8116          @nataliaprzc Con Liberaci√≥n se vive mejor   \n",
       "3409       15367  Bajando a Calahorra ya no queda nada para el c...   \n",
       "3410       10591              Es que estos dolores, son b√°rbaros...   \n",
       "3411        2111  #Chac√≥nenLaSER : \"Me siento con capacidad y co...   \n",
       "3413       13242  Por que existe gente bruta !!! Que cuando ven ...   \n",
       "\n",
       "      sentimiento                                  texto_normalizado  \\\n",
       "0               1                                      ['satisfech']   \n",
       "1               1  ['mejor', 'pas', 'navid', 'famili', 'amig', 'u...   \n",
       "2               1  ['planet', 'creativ', 'nuev', 'plac', 'interes...   \n",
       "3               0  ['necesit', 'ir', 'hog', 'dorm', 'dos', 'hij',...   \n",
       "4               1  ['xii', 'edicion', 'premi', 'cultur', 'extrema...   \n",
       "...           ...                                                ...   \n",
       "3408            1                          ['liber', 'viv', 'mejor']   \n",
       "3409            1  ['baj', 'calahorr', 'qued', 'cambi', 'junt', '...   \n",
       "3410            0                         ['dolor', 'barbar', '...']   \n",
       "3411            1  ['chaconenlas', 'sient', 'capac', 'equip', 'su...   \n",
       "3413            0  ['exist', 'gent', 'brut', 'ven', 'zapatill', '...   \n",
       "\n",
       "      prediccion   puntaje  \n",
       "0              1  0.800715  \n",
       "1              1  3.152403  \n",
       "2              1  6.140234  \n",
       "3              0 -1.191930  \n",
       "4              1  5.416284  \n",
       "...          ...       ...  \n",
       "3408           0 -0.339169  \n",
       "3409           1  1.845549  \n",
       "3410           0 -3.061629  \n",
       "3411           0 -0.282432  \n",
       "3413           0 -6.042320  \n",
       "\n",
       "[2313 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1834"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_nb[validation_nb['sentimiento'] == validation_nb['prediccion']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[966 216]\n",
      " [263 868]]\n",
      "Precision: [0.78600488 0.80073801]\n",
      "Recall: [0.81725888 0.76746242]\n",
      "Accuracy: 0.7929096411586684\n",
      "F1 Score: [0.80132725 0.78374718]\n"
     ]
    }
   ],
   "source": [
    "#Matriz de confusi√≥n\n",
    "cm = confusion_matrix(validation_nb['sentimiento'], validation_nb['prediccion'])\n",
    "\n",
    "precision = precision_score(validation_nb['sentimiento'], validation_nb['prediccion'], average=None)\n",
    "recall = recall_score(validation_nb['sentimiento'], validation_nb['prediccion'], average=None)\n",
    "accuracy = accuracy_score(validation_nb['sentimiento'], validation_nb['prediccion'])\n",
    "\n",
    "f1 = f1_score(validation_nb['sentimiento'], validation_nb['prediccion'], average=None)\n",
    "\n",
    "print(\"Matriz de confusi√≥n:\")\n",
    "print(cm)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
