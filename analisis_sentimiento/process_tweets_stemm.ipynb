{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11335/1685585545.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package snowball_data to\n",
      "[nltk_data]     /home/azul/nltk_data...\n",
      "[nltk_data]   Package snowball_data is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('snowball_data')\n",
    "stemmer = SnowballStemmer('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/azul/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sentiment_integrado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sentimiento\"] = df[\"sentimiento\"].apply(lambda x: x if x != \"Indefinido\" else \"Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappeo_sent = { \"Neutral\": 0, \"Negativo\": 1, \"Positivo\": 2}\n",
    "df[\"sentimiento\"] = df[\"sentimiento\"].apply(lambda x: mappeo_sent[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test_valid_data = train_test_split(df[['texto', 'sentimiento']].dropna(), test_size=0.4, random_state=42)\n",
    "test, validation = train_test_split(test_valid_data, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_tweets(tweet):\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stop_words and  # remove stopwords\n",
    "            word not in string.punctuation):  # remove punctuation\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return ' '.join(tweets_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimiento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10221</th>\n",
       "      <td>@Manuellflorod Bienvenida (triste) realidad, a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>Estar en los brazos de mi novio es lo único qu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7555</th>\n",
       "      <td>Todos tenemos un pasado @ahorapodemos ,que se ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7713</th>\n",
       "      <td>@ahorapodemos @ierrejon Tambien que las empres...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>En Islandia:  juicio a los responsables de la ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>El tono duro y sin concesiones de la réplica d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6331</th>\n",
       "      <td>Comienza su intervención en el acto de cierre ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bdías. EM no se ira de puente. Si vosotros os ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2647</th>\n",
       "      <td>#FF @ArturoGomezQuij, por demostrar en su penú...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5868</th>\n",
       "      <td>\"La herencia del @PSOE : trabajos a ratos y 5 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texto  sentimiento\n",
       "10221  @Manuellflorod Bienvenida (triste) realidad, a...            1\n",
       "9565   Estar en los brazos de mi novio es lo único qu...            2\n",
       "7555   Todos tenemos un pasado @ahorapodemos ,que se ...            0\n",
       "7713   @ahorapodemos @ierrejon Tambien que las empres...            2\n",
       "2825   En Islandia:  juicio a los responsables de la ...            0\n",
       "1038   El tono duro y sin concesiones de la réplica d...            1\n",
       "6331   Comienza su intervención en el acto de cierre ...            0\n",
       "10     Bdías. EM no se ira de puente. Si vosotros os ...            2\n",
       "2647   #FF @ArturoGomezQuij, por demostrar en su penú...            2\n",
       "5868   \"La herencia del @PSOE : trabajos a ratos y 5 ...            1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10221                      bienven trist realid andam mism\n",
       "9565                          braz novi unic quier necesit\n",
       "7555                                               pas dig\n",
       "7713     tambi empres independient contact si estub int...\n",
       "2825     islandi juici respons crisis negat pag deud el...\n",
       "1038     ton dur concesion replic rajoy amaiur anunci c...\n",
       "6331     comienz intervencion acto cierr campañ siguel ...\n",
       "10       bdi em ira puent si vais dejeis llev tablet pc...\n",
       "2647     ff demostr penultim tweet prejuici oportun act...\n",
       "5868     herenci trabaj rat 5 eur hor editorial 20.30 h...\n",
       "Name: texto, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10).texto.apply(lambda x: procesar_tweets(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['texto_procesado'] = train.texto.apply(lambda x: procesar_tweets(x))\n",
    "validation['texto_procesado'] = validation.texto.apply(lambda x: procesar_tweets(x))\n",
    "test['texto_procesado'] = test.texto.apply(lambda x: procesar_tweets(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texto</th>\n",
       "      <th>sentimiento</th>\n",
       "      <th>texto_procesado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10221</th>\n",
       "      <td>@Manuellflorod Bienvenida (triste) realidad, a...</td>\n",
       "      <td>1</td>\n",
       "      <td>[bienven, trist, realid, andam, mism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9565</th>\n",
       "      <td>Estar en los brazos de mi novio es lo único qu...</td>\n",
       "      <td>2</td>\n",
       "      <td>[braz, novi, unic, quier, necesit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7555</th>\n",
       "      <td>Todos tenemos un pasado @ahorapodemos ,que se ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[pas, dig]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7713</th>\n",
       "      <td>@ahorapodemos @ierrejon Tambien que las empres...</td>\n",
       "      <td>2</td>\n",
       "      <td>[tambi, empres, independient, contact, si, est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2825</th>\n",
       "      <td>En Islandia:  juicio a los responsables de la ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[islandi, juici, respons, crisis, negat, pag, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11285</th>\n",
       "      <td>No, solo quiero bailarte la medusa loca en pri...</td>\n",
       "      <td>2</td>\n",
       "      <td>[sol, quier, bailart, medus, loc, priv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11965</th>\n",
       "      <td>@cuervotinelli lo único que te puse fue que qu...</td>\n",
       "      <td>1</td>\n",
       "      <td>[unic, pus, quer, jug, lol, tortug, retwitt, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>La Audiencia Nacional condena a 20 años de pri...</td>\n",
       "      <td>1</td>\n",
       "      <td>[audienci, nacional, conden, 20, años, prision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>RT @eP_Titulares: #Sociedad Muere apuñalada la...</td>\n",
       "      <td>1</td>\n",
       "      <td>[socied, muer, apuñal, propietari, zapat, banyol]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15796</th>\n",
       "      <td>. @UPyD una sanidad y educación común y De cal...</td>\n",
       "      <td>2</td>\n",
       "      <td>[sanid, educ, comun, calid, español, 20nupyd, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10241 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texto  sentimiento  \\\n",
       "10221  @Manuellflorod Bienvenida (triste) realidad, a...            1   \n",
       "9565   Estar en los brazos de mi novio es lo único qu...            2   \n",
       "7555   Todos tenemos un pasado @ahorapodemos ,que se ...            0   \n",
       "7713   @ahorapodemos @ierrejon Tambien que las empres...            2   \n",
       "2825   En Islandia:  juicio a los responsables de la ...            0   \n",
       "...                                                  ...          ...   \n",
       "11285  No, solo quiero bailarte la medusa loca en pri...            2   \n",
       "11965  @cuervotinelli lo único que te puse fue que qu...            1   \n",
       "5390   La Audiencia Nacional condena a 20 años de pri...            1   \n",
       "860    RT @eP_Titulares: #Sociedad Muere apuñalada la...            1   \n",
       "15796  . @UPyD una sanidad y educación común y De cal...            2   \n",
       "\n",
       "                                         texto_procesado  \n",
       "10221              [bienven, trist, realid, andam, mism]  \n",
       "9565                  [braz, novi, unic, quier, necesit]  \n",
       "7555                                          [pas, dig]  \n",
       "7713   [tambi, empres, independient, contact, si, est...  \n",
       "2825   [islandi, juici, respons, crisis, negat, pag, ...  \n",
       "...                                                  ...  \n",
       "11285            [sol, quier, bailart, medus, loc, priv]  \n",
       "11965  [unic, pus, quer, jug, lol, tortug, retwitt, m...  \n",
       "5390   [audienci, nacional, conden, 20, años, prision...  \n",
       "860    [socied, muer, apuñal, propietari, zapat, banyol]  \n",
       "15796  [sanid, educ, comun, calid, español, 20nupyd, ...  \n",
       "\n",
       "[10241 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('processed_tweets_stemm/train.csv')\n",
    "validation.to_csv('processed_tweets_stemm/validation.csv')\n",
    "test.to_csv('processed_tweets_stemm/test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
